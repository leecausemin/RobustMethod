{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Reweight v1 (CRv1) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# 캐시된 모듈 제거\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if any(x in mod for x in ['NPR', 'npr', 'LGrad', 'lgrad', 'networks', 'method', 'channel_reweight']):\n",
    "        del sys.modules[mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.visual.visualizer import DatasetVisualizer\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# Channel Reweight v1 import\n",
    "from model.method import (\n",
    "    UnifiedChannelReweightV1,\n",
    "    ChannelReweightV1Config,\n",
    "    compute_channel_statistics,\n",
    ")\n",
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU and Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 30 08:14:02 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              27W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   59C    P0              40W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              27W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              25W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              27W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\"\n",
    "MODEL_LIST = [\"lgrad\", \"npr\"]\n",
    "MODEL = MODEL_LIST[0]  # \"lgrad\" or \"npr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"corrupted_dataset\"\n",
    "DATASETS = [\n",
    "    \"corrupted_test_data_progan\",\n",
    "    \"corrupted_test_data_stylegan\",\n",
    "    \"corrupted_test_data_stylegan2\",\n",
    "    \"corrupted_test_data_biggan\",\n",
    "    # \"corrupted_test_data_crn\",\n",
    "    # \"corrupted_test_data_cyclegan\",\n",
    "    # \"corrupted_test_data_deepfake\",\n",
    "    # \"corrupted_test_data_gaugan\",\n",
    "    # \"corrupted_test_data_imle\",\n",
    "    # \"corrupted_test_data_san\",\n",
    "    # \"corrupted_test_data_seeingdark\",\n",
    "    # \"corrupted_test_data_stargan\",\n",
    "    # \"corrupted_test_data_whichfaceisreal\",\n",
    "]\n",
    "\n",
    "CORRUPTIONS = [\n",
    "    \"original\",\n",
    "    \"gaussian_noise\",\n",
    "    \"jpeg_compression\",\n",
    "    # \"contrast\",\n",
    "    # \"fog\",\n",
    "    # \"motion_blur\",\n",
    "    # \"pixelate\",\n",
    "]\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 119874\n"
     ]
    }
   ],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root=ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(stylegan_weights, map_location=\"cpu\"),\n",
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(classifier_weights, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded: LGrad\n"
     ]
    }
   ],
   "source": [
    "# LGrad\n",
    "STYLEGAN_WEIGHTS_ROOT = \"model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "CLASSIFIER_WEIGHTS_ROOT = \"model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "\n",
    "# NPR\n",
    "NPR_WEIGHTS_ROOT = \"model/NPR/weights/NPR.pth\"\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    base_model = LGrad(\n",
    "        stylegan_weights=STYLEGAN_WEIGHTS_ROOT,\n",
    "        classifier_weights=CLASSIFIER_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name = \"LGrad\"\n",
    "elif MODEL == \"npr\":\n",
    "    base_model = NPR(\n",
    "        weights=NPR_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name = \"NPR\"\n",
    "\n",
    "print(f\"Base model loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Compute Channel Statistics from Clean Data\n",
    "\n",
    "**중요!** Channel Reweight v1은 clean data의 통계가 필요합니다.\n",
    "\n",
    "- ProGAN의 original (uncorrupted) 데이터로 statistics 수집\n",
    "- 한 번 계산하면 저장해서 재사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProGAN clean samples: 8000\n"
     ]
    }
   ],
   "source": [
    "# Clean data 준비 (ProGAN original)\n",
    "progan_clean_indices = [\n",
    "    i for i, s in enumerate(dataset.samples)\n",
    "    if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"original\"\n",
    "]\n",
    "\n",
    "print(f\"ProGAN clean samples: {len(progan_clean_indices)}\")\n",
    "\n",
    "# Subset & DataLoader\n",
    "clean_subset = Subset(dataset, progan_clean_indices)\n",
    "clean_loader = DataLoader(\n",
    "    clean_subset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing channel statistics from clean data (block-level)...\n",
      "This may take a few minutes...\n",
      "\n",
      "[CRv1] Computing statistics for 4 layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing statistics: 100%|██████████| 50/50 [00:17<00:00,  2.86it/s, batch=50/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classifier.layer1: C=256, mean_range=[0.0000, 2.1960], var_range=[0.0000, 0.3713]\n",
      "  classifier.layer2: C=512, mean_range=[0.0000, 1.9317], var_range=[0.0000, 1.1237]\n",
      "  classifier.layer3: C=1024, mean_range=[0.0000, 3.1548], var_range=[0.0000, 2.0396]\n",
      "  classifier.layer4: C=2048, mean_range=[0.0000, 2.2700], var_range=[0.0000, 2.3144]\n",
      "[CRv1] Statistics computed for 4 layers\n",
      "\n",
      "Statistics saved to clean_stats_lgrad_progan_blocks.pth\n"
     ]
    }
   ],
   "source": [
    "# Statistics 파일 경로 (block-level statistics)\n",
    "STATS_PATH = f\"clean_stats_{MODEL}_progan_blocks.pth\"\n",
    "\n",
    "# 기존 statistics가 있으면 로드, 없으면 계산\n",
    "if os.path.exists(STATS_PATH):\n",
    "    print(f\"Loading pre-computed statistics from {STATS_PATH}\")\n",
    "    clean_stats = torch.load(STATS_PATH)\n",
    "    print(f\"Statistics loaded for {len(clean_stats)} layers\")\n",
    "else:\n",
    "    print(\"Computing channel statistics from clean data (block-level)...\")\n",
    "    print(\"This may take a few minutes...\\n\")\n",
    "    \n",
    "    # Block 단위로 statistics 수집\n",
    "    target_layers_for_stats = [\n",
    "        'classifier.layer1',\n",
    "        'classifier.layer2',\n",
    "        'classifier.layer3',\n",
    "        'classifier.layer4',\n",
    "    ] if MODEL == \"lgrad\" else None\n",
    "    \n",
    "    clean_stats = compute_channel_statistics(\n",
    "        model=base_model,\n",
    "        dataloader=clean_loader,\n",
    "        target_layers=target_layers_for_stats,  # Block 단위로 지정\n",
    "        device=DEVICE,\n",
    "        max_batches=50,  # 속도를 위해 50 batches만 (필요하면 늘리기)\n",
    "    )\n",
    "    \n",
    "    # 저장\n",
    "    torch.save(clean_stats, STATS_PATH)\n",
    "    print(f\"\\nStatistics saved to {STATS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Channel Reweight v1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installed gate at classifier.layer1 (C=256)\n",
      "  Installed gate at classifier.layer2 (C=512)\n",
      "  Installed gate at classifier.layer3 (C=1024)\n",
      "  Installed gate at classifier.layer4 (C=2048)\n",
      "[CRv1] Initialized for LGrad\n",
      "[CRv1] Target layers: 4\n",
      "[CRv1] Temperature init: 2.0 (learnable=True)\n",
      "[CRv1] Channel bias: True\n",
      "[CRv1] Deviation metric: mean+var\n",
      "\n",
      "Channel Reweight v1 model created!\n"
     ]
    }
   ],
   "source": [
    "# Config 설정\n",
    "config = ChannelReweightV1Config(\n",
    "    model=model_name,\n",
    "    target_layers=[\n",
    "        'classifier.layer1',  # Block 전체 output [B, 256, 64, 64]\n",
    "        'classifier.layer2',  # Block 전체 output [B, 512, 32, 32]\n",
    "        'classifier.layer3',  # Block 전체 output [B, 1024, 16, 16]\n",
    "        'classifier.layer4',  # Block 전체 output [B, 2048, 8, 8]\n",
    "    ] if MODEL == \"lgrad\" else None,  # NPR은 None (auto-detect)\n",
    "    temperature_init=2.0,\n",
    "    use_learnable_temperature=True,\n",
    "    use_channel_bias=True,\n",
    "    deviation_metric=\"mean+var\",\n",
    "    normalize_deviation=True,\n",
    "    enable_adaptation=False,  # Test-time adaptation은 선택적\n",
    "    adaptation_lr=1e-4,\n",
    "    adaptation_loss=\"entropy\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Model 생성\n",
    "model = UnifiedChannelReweightV1(\n",
    "    base_model=base_model,\n",
    "    clean_stats=clean_stats,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"\\nChannel Reweight v1 model created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Test-Time Adaptation\n",
    "\n",
    "Noisy validation data로 temperature와 channel bias를 fine-tuning할 수 있습니다.\n",
    "\n",
    "**Skip 가능!** Adaptation 없이도 사용 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptation을 원하면 주석 해제\n",
    "# ENABLE_ADAPTATION = True\n",
    "\n",
    "# if ENABLE_ADAPTATION:\n",
    "#     # Noisy validation data 준비 (ProGAN gaussian_noise)\n",
    "#     progan_noisy_indices = [\n",
    "#         i for i, s in enumerate(dataset.samples)\n",
    "#         if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"gaussian_noise\"\n",
    "#     ]\n",
    "    \n",
    "#     print(f\"ProGAN noisy samples for adaptation: {len(progan_noisy_indices)}\")\n",
    "    \n",
    "#     noisy_subset = Subset(dataset, progan_noisy_indices[:500])  # 500개만 사용\n",
    "#     noisy_loader = DataLoader(\n",
    "#         noisy_subset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4,\n",
    "#         drop_last=False\n",
    "#     )\n",
    "    \n",
    "#     # Adaptation 실행\n",
    "#     print(\"\\nStarting test-time adaptation...\\n\")\n",
    "#     model.adapt(\n",
    "#         dataloader=noisy_loader,\n",
    "#         epochs=5,\n",
    "#         lr=1e-4,\n",
    "#         verbose=True,\n",
    "#     )\n",
    "#     print(\"\\nAdaptation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Dataset별, Corruption별로 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-original\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-original: 100%|██████████| 250/250 [01:31<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      3.03%\n",
      "  AP:       31.00%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-gaussian_noise\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-gaussian_noise: 100%|██████████| 250/250 [01:31<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      53.39%\n",
      "  AP:       54.28%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-jpeg_compression\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-jpeg_compression: 100%|██████████| 250/250 [01:31<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      61.91%\n",
      "  AP:       61.50%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan-original\n",
      "샘플 수: 11982\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan-original: 100%|██████████| 374/374 [02:17<00:00,  2.71it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.06%\n",
      "  AUC:      3.11%\n",
      "  AP:       30.95%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan-gaussian_noise\n",
      "샘플 수: 11982\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan-gaussian_noise: 100%|██████████| 374/374 [02:17<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.06%\n",
      "  AUC:      49.80%\n",
      "  AP:       49.54%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan-jpeg_compression\n",
      "샘플 수: 11982\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan-jpeg_compression: 100%|██████████| 374/374 [02:17<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.06%\n",
      "  AUC:      33.17%\n",
      "  AP:       39.76%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan2-original\n",
      "샘플 수: 15976\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan2-original: 100%|██████████| 499/499 [03:03<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.03%\n",
      "  AUC:      5.27%\n",
      "  AP:       31.30%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan2-gaussian_noise\n",
      "샘플 수: 15976\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan2-gaussian_noise: 100%|██████████| 499/499 [03:03<00:00,  2.72it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.03%\n",
      "  AUC:      39.86%\n",
      "  AP:       43.29%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan2-jpeg_compression\n",
      "샘플 수: 15976\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan2-jpeg_compression: 100%|██████████| 499/499 [03:03<00:00,  2.73it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.03%\n",
      "  AUC:      4.04%\n",
      "  AP:       31.05%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-original\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-original: 100%|██████████| 125/125 [00:46<00:00,  2.71it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      12.10%\n",
      "  AP:       32.35%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-gaussian_noise\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-gaussian_noise: 100%|██████████| 125/125 [00:46<00:00,  2.70it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      50.30%\n",
      "  AP:       51.14%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-jpeg_compression\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-jpeg_compression: 100%|██████████| 125/125 [00:46<00:00,  2.71it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      57.66%\n",
      "  AP:       58.88%\n",
      "  F1:       0.00%\n",
      "\n",
      "\n",
      "============================================================\n",
      "전체 결과 요약\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rich'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m전체 결과 요약\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mcalc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_results_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m calc.summarize_by_corruption(all_results)\n\u001b[32m     55\u001b[39m calc.summarize_by_dataset(all_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/utils/eval/metrics.py:185\u001b[39m, in \u001b[36mMetricsCalculator.print_results_table\u001b[39m\u001b[34m(self, results)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_results_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: \u001b[38;5;28mdict\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m    Print evaluation results in a formatted table\u001b[39;00m\n\u001b[32m    181\u001b[39m \n\u001b[32m    182\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m        results: dict from evaluate_by_combination() or use self.results_history\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrich\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconsole\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrich\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Table\n\u001b[32m    188\u001b[39m     console = Console()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rich'"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "calc = MetricsCalculator()\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        combination_indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] == corruption\n",
    "        ]\n",
    "        \n",
    "        if len(combination_indices) == 0:\n",
    "            print(f\"{dataset_name}-{corruption}: 샘플 없음, 스킵\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"평가 중: {dataset_name}-{corruption}\")\n",
    "        print(f\"샘플 수: {len(combination_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Subset과 DataLoader 생성\n",
    "        subset = Subset(dataset, combination_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # 평가\n",
    "        metrics = calc.evaluate(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "        \n",
    "        # 즉시 결과 출력\n",
    "        print(f\"\\n결과:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:      {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  AP:       {metrics['ap']*100:.2f}%\")\n",
    "        print(f\"  F1:       {metrics['f1']*100:.2f}%\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        all_results[(dataset_name, corruption)] = metrics\n",
    "\n",
    "# 전체 결과 테이블 출력\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"전체 결과 요약\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "calc.print_results_table()\n",
    "calc.summarize_by_corruption(all_results)\n",
    "calc.summarize_by_dataset(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learned Temperature 확인\n",
    "\n",
    "각 layer의 temperature가 어떻게 설정/학습되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Learned Temperatures\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for sanitized_name, gate in model.gates.items():\n",
    "    # Get original layer name\n",
    "    original_name = model.gate_name_mapping[sanitized_name]\n",
    "    temp_value = gate.temperature.item()\n",
    "    print(f\"{original_name:50s}: temperature = {temp_value:.4f}\")\n",
    "    \n",
    "    # Channel bias statistics\n",
    "    if config.use_channel_bias:\n",
    "        bias_mean = gate.channel_bias.mean().item()\n",
    "        bias_std = gate.channel_bias.std().item()\n",
    "        bias_min = gate.channel_bias.min().item()\n",
    "        bias_max = gate.channel_bias.max().item()\n",
    "        print(f\"{'':50s}  channel_bias: mean={bias_mean:+.4f}, std={bias_std:.4f}, range=[{bias_min:+.4f}, {bias_max:+.4f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Channel Reweight v1 핵심:\n",
    "\n",
    "1. **Clean data statistics 기반**: 노이즈 없는 데이터의 channel 통계를 기준점으로 사용\n",
    "2. **Noise sensitivity 측정**: Test time에 통계적 편차가 큰 channel = noise-sensitive\n",
    "3. **자동 가중치 조정**: Temperature & channel bias가 learnable → 수동 튜닝 불필요\n",
    "4. **선택적 adaptation**: Zero-shot으로도 사용 가능, adaptation으로 성능 향상 가능\n",
    "\n",
    "### 사용 Flow:\n",
    "```\n",
    "Clean data → compute_channel_statistics() → UnifiedChannelReweightV1\n",
    "                                                      ↓\n",
    "                                             (Optional) adapt()\n",
    "                                                      ↓\n",
    "                                              Inference & Eval\n",
    "```\n",
    "\n",
    "### 다음 단계:\n",
    "- NORM, SGS, SAS 등 다른 방법들과 성능 비교\n",
    "- Target layers 조합 실험 (layer3만? layer4만? 둘 다?)\n",
    "- NPR 모델에도 적용\n",
    "- Adaptation 효과 분석"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
