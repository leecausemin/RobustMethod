{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class-Conditional TTA-NRAM Example\n",
    "\n",
    "## ðŸŽ¯ Key Innovation: Separate NRAM for Real and Fake\n",
    "\n",
    "**Why Class-Conditional?**\n",
    "- âœ… **Real images**: Natural textures, specific statistical properties\n",
    "- âœ… **Fake images**: GAN artifacts, upsampling traces, different statistics  \n",
    "- âŒ **Problem**: Mixing them causes incorrect variance estimation\n",
    "- âœ… **Solution**: Separate NRAM modules optimized for each class\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input Image [B, 3, H, W]\n",
    "    â†“\n",
    "Base Model (frozen) â†’ layer4 features\n",
    "    â†“\n",
    "Pseudo-Label Generation (quick prediction)\n",
    "    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Real NRAM     â”‚   Fake NRAM     â”‚\n",
    "â”‚  (for real)     â”‚  (for fake)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â†“\n",
    "Merged Features â†’ Base Classifier\n",
    "```\n",
    "\n",
    "**Expected Improvement over Unified NRAM:**\n",
    "- Clean data: +1-2%\n",
    "- Noisy data: +5-10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Clear cache\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if any(x in mod for x in ['NPR', 'npr', 'LGrad', 'lgrad', 'tta_nram']):\n",
    "        del sys.modules[mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Dataset and metrics\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# Models\n",
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR\n",
    "\n",
    "# Class-Conditional TTA-NRAM\n",
    "from model.method.tta_nram import (\n",
    "    ClassConditionalTTANRAM,\n",
    "    TTANRAMConfig,\n",
    "    inference_with_tta_conditional,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Model selection\n",
    "MODEL = \"LGrad\"  # or \"NPR\"\n",
    "\n",
    "# Datasets and corruptions\n",
    "DATASETS = [\n",
    "    \"corrupted_test_data_progan\",\n",
    "    \"corrupted_test_data_stylegan\",\n",
    "]\n",
    "\n",
    "CORRUPTIONS = [\n",
    "    \"original\",\n",
    "    \"gaussian_noise\",\n",
    "    \"jpeg_compression\",\n",
    "]\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = \"corrupted_dataset\"\n",
    "\n",
    "# TTA config\n",
    "TTA_STEPS = 5\n",
    "TTA_LR = 1e-4\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == \"LGrad\":\n",
    "    STYLEGAN_WEIGHTS = \"model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "    CLASSIFIER_WEIGHTS = \"model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "    \n",
    "    base_model = LGrad(\n",
    "        stylegan_weights=STYLEGAN_WEIGHTS,\n",
    "        classifier_weights=CLASSIFIER_WEIGHTS,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "elif MODEL == \"NPR\":\n",
    "    NPR_WEIGHTS = \"model/NPR/weights/NPR.pth\"\n",
    "    \n",
    "    base_model = NPR(\n",
    "        weights=NPR_WEIGHTS,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "print(f\"âœ… {MODEL} base model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Class-Conditional TTA-NRAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "config = TTANRAMConfig(\n",
    "    model=MODEL,\n",
    "    target_layer=None,  # Auto-detect\n",
    "    reduction_ratio=16,\n",
    "    \n",
    "    # Noise estimation\n",
    "    noise_detection_method=\"laplacian\",\n",
    "    noise_normalize_factor=100.0,\n",
    "    \n",
    "    # Memory bank (class-specific)\n",
    "    enable_memory_bank=True,\n",
    "    memory_size=100,\n",
    "    confidence_threshold=0.8,\n",
    "    \n",
    "    # TTA settings\n",
    "    tta_steps=TTA_STEPS,\n",
    "    tta_lr=TTA_LR,\n",
    "    tta_loss_weights={\"entropy\": 1.0, \"confidence\": 0.1},\n",
    "    \n",
    "    # Gating\n",
    "    residual_weight=0.1,\n",
    "    \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Create class-conditional model\n",
    "tta_model = ClassConditionalTTANRAM(base_model, config)\n",
    "\n",
    "print(\"âœ… ClassConditionalTTANRAM created\")\n",
    "print(f\"   - Real NRAM: {sum(p.numel() for p in tta_model.real_nram.parameters()):,} params\")\n",
    "print(f\"   - Fake NRAM: {sum(p.numel() for p in tta_model.fake_nram.parameters()):,} params\")\n",
    "print(f\"   - Total trainable: {sum(p.numel() for p in tta_model.parameters() if p.requires_grad):,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root=DATA_ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Datasets: {DATASETS}\")\n",
    "print(f\"Corruptions: {CORRUPTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test on Single Batch\n",
    "\n",
    "Let's see pseudo-label routing in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch with mixed real/fake\n",
    "noisy_indices = [\n",
    "    i for i, s in enumerate(dataset.samples)\n",
    "    if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"gaussian_noise\"\n",
    "]\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Subset(dataset, noisy_indices[:32]),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "images, labels, metadata = batch\n",
    "images = images.to(DEVICE)\n",
    "labels = labels.to(DEVICE)\n",
    "\n",
    "print(f\"Batch size: {images.shape[0]}\")\n",
    "print(f\"Ground truth: Real={( labels==0).sum().item()}, Fake={(labels==1).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA with class-conditional routing\n",
    "tta_model.reset_memory()\n",
    "\n",
    "print(\"Running Class-Conditional TTA...\")\n",
    "results = inference_with_tta_conditional(\n",
    "    model=tta_model,\n",
    "    images=images,\n",
    "    config=config,\n",
    "    return_debug=True\n",
    ")\n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Class-Conditional TTA Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Initial predictions (mean): {results['initial_predictions'].mean().item():.4f}\")\n",
    "print(f\"Final predictions (mean):   {results['predictions'].mean().item():.4f}\")\n",
    "print(f\"Improvement:                {results['improvement']:.4f}\")\n",
    "\n",
    "# Pseudo-labels\n",
    "pseudo_labels = results['pseudo_labels']\n",
    "print(f\"\\nPseudo-labels: Real={( pseudo_labels==0).sum().item()}, Fake={(pseudo_labels==1).sum().item()}\")\n",
    "print(f\"Ground truth:  Real={( labels.cpu()==0).sum().item()}, Fake={(labels.cpu()==1).sum().item()}\")\n",
    "\n",
    "# Pseudo-label accuracy\n",
    "pseudo_acc = (pseudo_labels == labels.cpu()).float().mean().item()\n",
    "print(f\"Pseudo-label accuracy: {pseudo_acc*100:.2f}%\")\n",
    "\n",
    "# TTA history\n",
    "print(\"\\nTTA History (class-wise):\")\n",
    "for step_info in results['tta_history']:\n",
    "    print(f\"  Step {step_info['step']}: loss={step_info['loss']:.4f}, \"\n",
    "          f\"real={step_info.get('n_real', 0)}, fake={step_info.get('n_fake', 0)}\")\n",
    "\n",
    "# Final accuracy\n",
    "preds = (results['predictions'] > 0.5).float().squeeze()\n",
    "acc = (preds == labels.cpu().float()).float().mean().item()\n",
    "print(f\"\\nFinal Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Evaluation\n",
    "\n",
    "Evaluate on all dataset-corruption combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_class_conditional(model, dataloader, config, device, name=\"test\"):\n",
    "    \"\"\"\n",
    "    Evaluate ClassConditionalTTANRAM on dataloader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    collector = PredictionCollector()\n",
    "    calc = MetricsCalculator()\n",
    "    \n",
    "    # Reset memory\n",
    "    model.reset_memory()\n",
    "    \n",
    "    # Track pseudo-label accuracy\n",
    "    pseudo_correct = 0\n",
    "    pseudo_total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=name)\n",
    "    for batch in pbar:\n",
    "        images, labels, metadata = batch\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Class-conditional TTA\n",
    "        results = inference_with_tta_conditional(\n",
    "            model=model,\n",
    "            images=images,\n",
    "            config=config,\n",
    "            return_debug=False\n",
    "        )\n",
    "        \n",
    "        # Collect predictions\n",
    "        probs = results['predictions']\n",
    "        collector.update(labels, probs, threshold=0.5)\n",
    "        \n",
    "        # Track pseudo-label accuracy\n",
    "        if results['pseudo_labels'] is not None:\n",
    "            pseudo_labels = results['pseudo_labels']\n",
    "            pseudo_correct += (pseudo_labels == labels).sum().item()\n",
    "            pseudo_total += len(labels)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = calc.compute_from_collector(collector, name=name)\n",
    "    \n",
    "    # Add pseudo-label accuracy\n",
    "    if pseudo_total > 0:\n",
    "        metrics['pseudo_label_acc'] = pseudo_correct / pseudo_total\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all combinations\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] == corruption\n",
    "        ]\n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Evaluating: {dataset_name}-{corruption}\")\n",
    "        print(f\"Samples: {len(indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_class_conditional(\n",
    "            model=tta_model,\n",
    "            dataloader=dataloader,\n",
    "            config=config,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Accuracy:          {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:               {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  F1:                {metrics['f1']*100:.2f}%\")\n",
    "        print(f\"  Pseudo-label acc:  {metrics.get('pseudo_label_acc', 0)*100:.2f}%\")\n",
    "        \n",
    "        all_results[(dataset_name, corruption)] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Class-conditional TTA-NRAM improves robustness by:\n",
    "1. **Separating Real and Fake processing** (different feature statistics)\n",
    "2. **Pseudo-label based routing** (automatic classification)\n",
    "3. **Class-specific memory banks** (robust statistics per class)\n",
    "4. **Independent optimization** (each NRAM adapts to its class)\n",
    "\n",
    "**Expected improvements over UnifiedTTANRAM:**\n",
    "- Better variance estimation\n",
    "- More targeted noise suppression\n",
    "- Higher accuracy on both clean and noisy data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
