{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4f61aa",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ed013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# 캐시된 모듈 제거\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if 'NPR' in mod or 'npr' in mod or 'networks' in mod:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "# 이제 정상적으로 import\n",
    "from model.NPR.npr_model import NPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e2435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if any(x in mod for x in ['NPR', 'npr', 'networks', 'sgs', 'method']):\n",
    "        del sys.modules[mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2585317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "from typing import Optional, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.visual.visualizer import DatasetVisualizer\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# SGS method import\n",
    "# from model.method.sgs import LGradSGS, SGSConfig\n",
    "from model.LGrad.lgrad_model import LGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c327e",
   "metadata": {},
   "source": [
    "# GPU and Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1212de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 29 15:06:25 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              33W / 250W |    260MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   49C    P0              26W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              27W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              25W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              26W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              27W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf394e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:1\"\n",
    "MODEL_LIST = [\"lgrad\", \"npr\"]\n",
    "MODEL = MODEL_LIST[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d73d",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d50a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"corrupted_dataset\"\n",
    "DATASETS = [\"corrupted_test_data_biggan\", \"corrupted_test_data_crn\", \"corrupted_test_data_cyclegan\", \"corrupted_test_data_deepfake\", \"corrupted_test_data_gaugan\", \"corrupted_test_data_imle\", \"corrupted_test_data_progan\", \"corrupted_test_data_san\", \"corrupted_test_data_seeingdark\", \"corrupted_test_data_stargan\", \"corrupted_test_data_stylegan\", \"corrupted_test_data_stylegan2\", \"corrupted_test_data_whichfaceisreal\"]\n",
    "CORRUPTIONS = [\"original\", \"gaussian_noise\", \"jpeg_compression\"] # , \"contrast\", \"fog\", , \"motion_blur\", \"pixelate\"\n",
    "if MODEL == \"lgrad\":\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(224), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5739f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 270987\n"
     ]
    }
   ],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root= ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2f66d",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bec3d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(stylegan_weights, map_location=\"cpu\"),\n",
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(classifier_weights, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR\n",
    "\n",
    "#LGrad\n",
    "STYLEGAN_WEIGHTS_ROOT=\"model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "CLASSIFIER_WEIGHTS_ROOT=\"model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "\n",
    "#NPR\n",
    "NPR_WEIGHTS_ROOT=\"model/NPR/weights/NPR.pth\"\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    model = LGrad(\n",
    "        stylegan_weights=STYLEGAN_WEIGHTS_ROOT,\n",
    "        classifier_weights=CLASSIFIER_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name=\"LGrad\"\n",
    "    LAMBDA=0.03\n",
    "    DELTA=0.01\n",
    "    ITERATIONS=5\n",
    "    STEP_SIZE=0.1\n",
    "elif MODEL == \"npr\":\n",
    "    model = NPR(\n",
    "        weights=NPR_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name=\"NPR\"\n",
    "    LAMBDA=0.005\n",
    "    DELTA=0.01\n",
    "    ITERATIONS=3\n",
    "    STEP_SIZE=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199d0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.method.sgs import SGSConfig, UnifiedSGS\n",
    "from model.method.sas import UnifiedSAS, SASConfig\n",
    "from model.method.sgsv2 import UnifiedSGSv2, SGSv2Config\n",
    "# sgs_config = SGSConfig(\n",
    "#     K=4,\n",
    "#     model=model_name,\n",
    "#     denoise_target=\"artifact\",\n",
    "#     huber_tv_lambda=LAMBDA,\n",
    "#     huber_tv_delta=DELTA,\n",
    "#     huber_tv_iterations=ITERATIONS,\n",
    "#     huber_tv_step_size=STEP_SIZE,\n",
    "\n",
    "#     device=DEVICE,\n",
    "# )\n",
    "\n",
    "# sas_config = SASConfig(\n",
    "#     K=5,\n",
    "#     model=model_name,\n",
    "#     denoise_target=\"artifact\",\n",
    "#     lambda_range=(0.3, 2.0),\n",
    "#     jitter_strength=0.2,\n",
    "\n",
    "#     # Huber-TV\n",
    "#     huber_tv_lambda=0.05,\n",
    "#     huber_tv_delta=0.01,\n",
    "\n",
    "    \n",
    "#     fusion_scale=2.0,\n",
    "#     device=DEVICE,\n",
    "# )\n",
    "\n",
    "# sasv2_config = SGSv2Config(\n",
    "#     K=5,\n",
    "#     model=model_name,\n",
    "#     denoise_target=\"artifact\",\n",
    "\n",
    "#     fusion_alpha=0.3,\n",
    "#     beta_threshold=0.02,\n",
    "#     beta_softness=0.01,\n",
    "\n",
    "#     device=DEVICE\n",
    "# )\n",
    "\n",
    "# model = UnifiedSGSv2(model, sasv2_config) # 실제로는 SASv2이지만 이름 잘못 설정함\n",
    "\n",
    "# model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c986b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.method.sasv3 import UnifiedSASv3, SASv3Config\n",
    "\n",
    "# config = SASv3Config(\n",
    "#     K=5,\n",
    "#     model=\"LGrad\",\n",
    "#     denoise_target=\"artifact\",\n",
    "#     fusion_method=\"robust\",\n",
    "#     fusion_scale=2.0,\n",
    "#     adaptive_beta=True,\n",
    "#     beta_method=\"auto\",  # Calibration으로 자동\n",
    "#     device=DEVICE\n",
    "# )\n",
    "\n",
    "# model = UnifiedSASv3(model, config)\n",
    "# model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a161bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.method import UnifiedSASv4, SASv4Config\n",
    "\n",
    "# config = SASv4Config(\n",
    "#     K=5,\n",
    "#     model=\"LGrad\",\n",
    "#     denoise_target=\"artifact\",\n",
    "#     residual_beta=1.0,\n",
    "#     dmap_percentile=95.0,\n",
    "#     device=DEVICE,\n",
    "# )\n",
    "\n",
    "# model = UnifiedSASv4(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baeb3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.method import UnifiedSASv5, SASv5Config, create_lgrad_sasv5\n",
    "\n",
    "# config = SASv5Config(\n",
    "#     K=3,\n",
    "#     model=\"LGrad\",\n",
    "#     sigmas=[0.0, 0.8, 1.6],  # Gaussian blur σ\n",
    "#     denoise_target=\"artifact\",  # GoG!\n",
    "#     residual_beta=1.0,\n",
    "#     device=DEVICE,\n",
    "# )\n",
    "\n",
    "# model = UnifiedSASv5(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0816725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v5, v4를 위함\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# progan_clean_indices = [\n",
    "#     i for i, s in enumerate(dataset.samples)\n",
    "#     if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"original\"\n",
    "# ]\n",
    "\n",
    "# print(f\"ProGAN clean samples: {len(progan_clean_indices)}\")\n",
    "\n",
    "# # ===== 5. Subset & DataLoader 생성 =====\n",
    "# clean_subset = Subset(dataset, progan_clean_indices)\n",
    "# clean_loader = DataLoader(\n",
    "#     clean_subset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "#     drop_last=False  # Calibration은 drop_last=False\n",
    "# )\n",
    "\n",
    "# model.calibrate_disagreement_threshold(clean_loader, percentile=95.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f021104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SASv6] Initialized for LGrad\n",
      "[SASv6] Gaussian: kernel=3, σ=0.8\n",
      "[SASv6] Block DCT: thresh=2.5, clip=10.0\n",
      "[SASv6] DWT: type=haar, λ=0.05\n",
      "[SASv6] Input mode: I_d_wave\n",
      "[SASv6] Residual type: R_d\n"
     ]
    }
   ],
   "source": [
    "from model.method import UnifiedSASv6, SASv6Config\n",
    "\n",
    "config = SASv6Config(\n",
    "    model=\"LGrad\",\n",
    "    gaussian_sigma=0.8,\n",
    "    dct_threshold=2.5,\n",
    "    dwt_threshold=0.05,\n",
    "    # ===== DWT 비활성화 =====\n",
    "    apply_dwt_to_input=False,     # I_d에 DWT 적용 안함\n",
    "    apply_dwt_to_residual=False,  # R_d에 DWT 적용 안함\n",
    "    input_mode=\"I_d_wave\",\n",
    "    # residual_type=\"R_d\",\n",
    "    device=DEVICE\n",
    ")\n",
    "model = UnifiedSASv6(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04296f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Identity-1          [-1, 3, 256, 256]               0\n",
      "          Identity-2          [-1, 3, 256, 256]               0\n",
      "          Identity-3         [-1, 64, 256, 256]               0\n",
      "         LeakyReLU-4         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-5         [-1, 64, 256, 256]             256\n",
      "          Identity-6         [-1, 64, 256, 256]               0\n",
      "          Identity-7         [-1, 64, 256, 256]               0\n",
      "          Identity-8         [-1, 64, 256, 256]               0\n",
      "         LeakyReLU-9         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-10         [-1, 64, 256, 256]          36,928\n",
      "         Identity-11         [-1, 64, 256, 256]               0\n",
      "        BlurLayer-12         [-1, 64, 256, 256]               0\n",
      "         Identity-13        [-1, 128, 128, 128]               0\n",
      "        LeakyReLU-14        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-15        [-1, 128, 128, 128]          73,856\n",
      "         Identity-16        [-1, 128, 128, 128]               0\n",
      "         Identity-17        [-1, 128, 128, 128]               0\n",
      "         Identity-18        [-1, 128, 128, 128]               0\n",
      "        LeakyReLU-19        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-20        [-1, 128, 128, 128]         147,584\n",
      "         Identity-21        [-1, 128, 128, 128]               0\n",
      "        BlurLayer-22        [-1, 128, 128, 128]               0\n",
      "         Identity-23          [-1, 256, 64, 64]               0\n",
      "        LeakyReLU-24          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-25          [-1, 256, 64, 64]         295,168\n",
      "         Identity-26          [-1, 256, 64, 64]               0\n",
      "         Identity-27          [-1, 256, 64, 64]               0\n",
      "         Identity-28          [-1, 256, 64, 64]               0\n",
      "        LeakyReLU-29          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-30          [-1, 256, 64, 64]         590,080\n",
      "         Identity-31          [-1, 256, 64, 64]               0\n",
      "        BlurLayer-32          [-1, 256, 64, 64]               0\n",
      "DownsamplingLayer-33          [-1, 512, 32, 32]               0\n",
      "        LeakyReLU-34          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-35          [-1, 512, 32, 32]       1,180,160\n",
      "         Identity-36          [-1, 512, 32, 32]               0\n",
      "         Identity-37          [-1, 512, 32, 32]               0\n",
      "         Identity-38          [-1, 512, 32, 32]               0\n",
      "        LeakyReLU-39          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-40          [-1, 512, 32, 32]       2,359,808\n",
      "         Identity-41          [-1, 512, 32, 32]               0\n",
      "        BlurLayer-42          [-1, 512, 32, 32]               0\n",
      "DownsamplingLayer-43          [-1, 512, 16, 16]               0\n",
      "        LeakyReLU-44          [-1, 512, 16, 16]               0\n",
      "        ConvBlock-45          [-1, 512, 16, 16]       2,359,808\n",
      "         Identity-46          [-1, 512, 16, 16]               0\n",
      "         Identity-47          [-1, 512, 16, 16]               0\n",
      "         Identity-48          [-1, 512, 16, 16]               0\n",
      "        LeakyReLU-49          [-1, 512, 16, 16]               0\n",
      "        ConvBlock-50          [-1, 512, 16, 16]       2,359,808\n",
      "         Identity-51          [-1, 512, 16, 16]               0\n",
      "        BlurLayer-52          [-1, 512, 16, 16]               0\n",
      "DownsamplingLayer-53            [-1, 512, 8, 8]               0\n",
      "        LeakyReLU-54            [-1, 512, 8, 8]               0\n",
      "        ConvBlock-55            [-1, 512, 8, 8]       2,359,808\n",
      "         Identity-56            [-1, 512, 8, 8]               0\n",
      "         Identity-57            [-1, 512, 8, 8]               0\n",
      "         Identity-58            [-1, 512, 8, 8]               0\n",
      "        LeakyReLU-59            [-1, 512, 8, 8]               0\n",
      "        ConvBlock-60            [-1, 512, 8, 8]       2,359,808\n",
      "         Identity-61            [-1, 512, 8, 8]               0\n",
      "        BlurLayer-62            [-1, 512, 8, 8]               0\n",
      "DownsamplingLayer-63            [-1, 512, 4, 4]               0\n",
      "        LeakyReLU-64            [-1, 512, 4, 4]               0\n",
      "        ConvBlock-65            [-1, 512, 4, 4]       2,359,808\n",
      "MiniBatchSTDLayer-66            [-1, 513, 4, 4]               0\n",
      "         Identity-67            [-1, 513, 4, 4]               0\n",
      "         Identity-68            [-1, 512, 4, 4]               0\n",
      "        LeakyReLU-69            [-1, 512, 4, 4]               0\n",
      "        ConvBlock-70            [-1, 512, 4, 4]       2,364,416\n",
      "        LeakyReLU-71                  [-1, 512]               0\n",
      "       DenseBlock-72                  [-1, 512]       4,194,816\n",
      "         Identity-73                    [-1, 1]               0\n",
      "       DenseBlock-74                    [-1, 1]             513\n",
      "StyleGANDiscriminator-75                    [-1, 1]               0\n",
      "           Conv2d-76         [-1, 64, 128, 128]           9,408\n",
      "      BatchNorm2d-77         [-1, 64, 128, 128]             128\n",
      "             ReLU-78         [-1, 64, 128, 128]               0\n",
      "        MaxPool2d-79           [-1, 64, 64, 64]               0\n",
      "           Conv2d-80           [-1, 64, 64, 64]           4,096\n",
      "      BatchNorm2d-81           [-1, 64, 64, 64]             128\n",
      "             ReLU-82           [-1, 64, 64, 64]               0\n",
      "           Conv2d-83           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-84           [-1, 64, 64, 64]             128\n",
      "             ReLU-85           [-1, 64, 64, 64]               0\n",
      "           Conv2d-86          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-87          [-1, 256, 64, 64]             512\n",
      "           Conv2d-88          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-89          [-1, 256, 64, 64]             512\n",
      "             ReLU-90          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-91          [-1, 256, 64, 64]               0\n",
      "           Conv2d-92           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-93           [-1, 64, 64, 64]             128\n",
      "             ReLU-94           [-1, 64, 64, 64]               0\n",
      "           Conv2d-95           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-96           [-1, 64, 64, 64]             128\n",
      "             ReLU-97           [-1, 64, 64, 64]               0\n",
      "           Conv2d-98          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-99          [-1, 256, 64, 64]             512\n",
      "            ReLU-100          [-1, 256, 64, 64]               0\n",
      "      Bottleneck-101          [-1, 256, 64, 64]               0\n",
      "          Conv2d-102           [-1, 64, 64, 64]          16,384\n",
      "     BatchNorm2d-103           [-1, 64, 64, 64]             128\n",
      "            ReLU-104           [-1, 64, 64, 64]               0\n",
      "          Conv2d-105           [-1, 64, 64, 64]          36,864\n",
      "     BatchNorm2d-106           [-1, 64, 64, 64]             128\n",
      "            ReLU-107           [-1, 64, 64, 64]               0\n",
      "          Conv2d-108          [-1, 256, 64, 64]          16,384\n",
      "     BatchNorm2d-109          [-1, 256, 64, 64]             512\n",
      "            ReLU-110          [-1, 256, 64, 64]               0\n",
      "      Bottleneck-111          [-1, 256, 64, 64]               0\n",
      "          Conv2d-112          [-1, 128, 64, 64]          32,768\n",
      "     BatchNorm2d-113          [-1, 128, 64, 64]             256\n",
      "            ReLU-114          [-1, 128, 64, 64]               0\n",
      "          Conv2d-115          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-116          [-1, 128, 32, 32]             256\n",
      "            ReLU-117          [-1, 128, 32, 32]               0\n",
      "          Conv2d-118          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-119          [-1, 512, 32, 32]           1,024\n",
      "          Conv2d-120          [-1, 512, 32, 32]         131,072\n",
      "     BatchNorm2d-121          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-122          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-123          [-1, 512, 32, 32]               0\n",
      "          Conv2d-124          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-125          [-1, 128, 32, 32]             256\n",
      "            ReLU-126          [-1, 128, 32, 32]               0\n",
      "          Conv2d-127          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-128          [-1, 128, 32, 32]             256\n",
      "            ReLU-129          [-1, 128, 32, 32]               0\n",
      "          Conv2d-130          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-131          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-132          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-133          [-1, 512, 32, 32]               0\n",
      "          Conv2d-134          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-135          [-1, 128, 32, 32]             256\n",
      "            ReLU-136          [-1, 128, 32, 32]               0\n",
      "          Conv2d-137          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-138          [-1, 128, 32, 32]             256\n",
      "            ReLU-139          [-1, 128, 32, 32]               0\n",
      "          Conv2d-140          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-141          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-142          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-143          [-1, 512, 32, 32]               0\n",
      "          Conv2d-144          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-145          [-1, 128, 32, 32]             256\n",
      "            ReLU-146          [-1, 128, 32, 32]               0\n",
      "          Conv2d-147          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-148          [-1, 128, 32, 32]             256\n",
      "            ReLU-149          [-1, 128, 32, 32]               0\n",
      "          Conv2d-150          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-151          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-152          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-153          [-1, 512, 32, 32]               0\n",
      "          Conv2d-154          [-1, 256, 32, 32]         131,072\n",
      "     BatchNorm2d-155          [-1, 256, 32, 32]             512\n",
      "            ReLU-156          [-1, 256, 32, 32]               0\n",
      "          Conv2d-157          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 16, 16]             512\n",
      "            ReLU-159          [-1, 256, 16, 16]               0\n",
      "          Conv2d-160         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 16, 16]           2,048\n",
      "          Conv2d-162         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-163         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-164         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-165         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-166          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-167          [-1, 256, 16, 16]             512\n",
      "            ReLU-168          [-1, 256, 16, 16]               0\n",
      "          Conv2d-169          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-170          [-1, 256, 16, 16]             512\n",
      "            ReLU-171          [-1, 256, 16, 16]               0\n",
      "          Conv2d-172         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-173         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-174         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-175         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-176          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 16, 16]             512\n",
      "            ReLU-178          [-1, 256, 16, 16]               0\n",
      "          Conv2d-179          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 16, 16]             512\n",
      "            ReLU-181          [-1, 256, 16, 16]               0\n",
      "          Conv2d-182         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-184         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-185         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-186          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-187          [-1, 256, 16, 16]             512\n",
      "            ReLU-188          [-1, 256, 16, 16]               0\n",
      "          Conv2d-189          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-190          [-1, 256, 16, 16]             512\n",
      "            ReLU-191          [-1, 256, 16, 16]               0\n",
      "          Conv2d-192         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-193         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-194         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-195         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-196          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-197          [-1, 256, 16, 16]             512\n",
      "            ReLU-198          [-1, 256, 16, 16]               0\n",
      "          Conv2d-199          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-200          [-1, 256, 16, 16]             512\n",
      "            ReLU-201          [-1, 256, 16, 16]               0\n",
      "          Conv2d-202         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-203         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-204         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-205         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-206          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-207          [-1, 256, 16, 16]             512\n",
      "            ReLU-208          [-1, 256, 16, 16]               0\n",
      "          Conv2d-209          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-210          [-1, 256, 16, 16]             512\n",
      "            ReLU-211          [-1, 256, 16, 16]               0\n",
      "          Conv2d-212         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-213         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-214         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-215         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-216          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-217          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-218          [-1, 512, 16, 16]               0\n",
      "          Conv2d-219            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-220            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-221            [-1, 512, 8, 8]               0\n",
      "          Conv2d-222           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-223           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-224           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-225           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-226           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-227           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-228            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-229            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-230            [-1, 512, 8, 8]               0\n",
      "          Conv2d-231            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-232            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-233            [-1, 512, 8, 8]               0\n",
      "          Conv2d-234           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-235           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-236           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-237           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-238            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-239            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-240            [-1, 512, 8, 8]               0\n",
      "          Conv2d-241            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-242            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-243            [-1, 512, 8, 8]               0\n",
      "          Conv2d-244           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-245           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-246           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-247           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-248           [-1, 2048, 1, 1]               0\n",
      "          Linear-249                    [-1, 1]           2,049\n",
      "          ResNet-250                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 46,552,706\n",
      "Trainable params: 46,552,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 990.27\n",
      "Params size (MB): 177.58\n",
      "Estimated Total Size (MB): 1168.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c722a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-original\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-original: 100%|██████████| 250/250 [00:47<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.95%\n",
      "  AUC:      46.56%\n",
      "  AP:       47.39%\n",
      "  F1:       1.86%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-gaussian_noise\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-gaussian_noise: 100%|██████████| 250/250 [00:47<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.05%\n",
      "  AUC:      50.55%\n",
      "  AP:       51.59%\n",
      "  F1:       0.20%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-jpeg_compression\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-jpeg_compression: 100%|██████████| 250/250 [00:47<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.55%\n",
      "  AUC:      47.10%\n",
      "  AP:       49.39%\n",
      "  F1:       4.07%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_crn-original\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_crn-original: 100%|██████████| 797/797 [02:31<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.44%\n",
      "  AUC:      51.56%\n",
      "  AP:       47.89%\n",
      "  F1:       0.40%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_crn-gaussian_noise\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_crn-gaussian_noise: 100%|██████████| 797/797 [02:31<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.04%\n",
      "  AUC:      53.86%\n",
      "  AP:       52.74%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_crn-jpeg_compression\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_crn-jpeg_compression: 100%|██████████| 797/797 [02:31<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.02%\n",
      "  AUC:      54.81%\n",
      "  AP:       50.74%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_cyclegan-original\n",
      "샘플 수: 2642\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_cyclegan-original: 100%|██████████| 165/165 [00:31<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.58%\n",
      "  AUC:      51.02%\n",
      "  AP:       50.07%\n",
      "  F1:       1.63%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_cyclegan-gaussian_noise\n",
      "샘플 수: 2642\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_cyclegan-gaussian_noise: 100%|██████████| 165/165 [00:31<00:00,  5.22it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.04%\n",
      "  AUC:      46.85%\n",
      "  AP:       48.00%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_cyclegan-jpeg_compression\n",
      "샘플 수: 2642\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_cyclegan-jpeg_compression: 100%|██████████| 165/165 [00:31<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.92%\n",
      "  AUC:      49.41%\n",
      "  AP:       50.64%\n",
      "  F1:       2.79%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_deepfake-original\n",
      "샘플 수: 5405\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_deepfake-original: 100%|██████████| 337/337 [01:04<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.85%\n",
      "  AUC:      47.50%\n",
      "  AP:       48.50%\n",
      "  F1:       18.36%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_deepfake-gaussian_noise\n",
      "샘플 수: 5405\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_deepfake-gaussian_noise: 100%|██████████| 337/337 [01:04<00:00,  5.24it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.20%\n",
      "  AUC:      48.64%\n",
      "  AP:       48.61%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_deepfake-jpeg_compression\n",
      "샘플 수: 5405\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_deepfake-jpeg_compression: 100%|██████████| 337/337 [01:04<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.09%\n",
      "  AUC:      47.87%\n",
      "  AP:       48.79%\n",
      "  F1:       5.74%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_gaugan-original\n",
      "샘플 수: 10000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_gaugan-original: 100%|██████████| 625/625 [01:58<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.92%\n",
      "  AUC:      55.47%\n",
      "  AP:       53.43%\n",
      "  F1:       2.23%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_gaugan-gaussian_noise\n",
      "샘플 수: 10000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_gaugan-gaussian_noise: 100%|██████████| 625/625 [01:59<00:00,  5.25it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      44.63%\n",
      "  AP:       46.66%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_gaugan-jpeg_compression\n",
      "샘플 수: 10000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_gaugan-jpeg_compression: 100%|██████████| 625/625 [01:59<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.81%\n",
      "  AUC:      53.55%\n",
      "  AP:       50.84%\n",
      "  F1:       0.71%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_imle-original\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_imle-original: 100%|██████████| 797/797 [02:31<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.44%\n",
      "  AUC:      51.89%\n",
      "  AP:       47.84%\n",
      "  F1:       0.40%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_imle-gaussian_noise\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_imle-gaussian_noise: 100%|██████████| 797/797 [02:31<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.05%\n",
      "  AUC:      50.06%\n",
      "  AP:       51.09%\n",
      "  F1:       0.03%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_imle-jpeg_compression\n",
      "샘플 수: 12764\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_imle-jpeg_compression: 100%|██████████| 797/797 [02:31<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.02%\n",
      "  AUC:      47.73%\n",
      "  AP:       45.80%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-original\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-original: 100%|██████████| 500/500 [01:35<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 51.49%\n",
      "  AUC:      60.02%\n",
      "  AP:       59.28%\n",
      "  F1:       9.81%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-gaussian_noise\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-gaussian_noise: 100%|██████████| 500/500 [01:35<00:00,  5.24it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.00%\n",
      "  AUC:      49.15%\n",
      "  AP:       49.44%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_progan-jpeg_compression\n",
      "샘플 수: 8000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_progan-jpeg_compression: 100%|██████████| 500/500 [01:35<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.21%\n",
      "  AUC:      51.46%\n",
      "  AP:       51.71%\n",
      "  F1:       2.78%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_san-original\n",
      "샘플 수: 438\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_san-original: 100%|██████████| 27/27 [00:05<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 49.31%\n",
      "  AUC:      48.15%\n",
      "  AP:       47.21%\n",
      "  F1:       6.81%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_san-gaussian_noise\n",
      "샘플 수: 438\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_san-gaussian_noise: 100%|██████████| 27/27 [00:05<00:00,  4.74it/s]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.69%\n",
      "  AUC:      46.06%\n",
      "  AP:       47.32%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_san-jpeg_compression\n",
      "샘플 수: 438\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_san-jpeg_compression: 100%|██████████| 27/27 [00:05<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.46%\n",
      "  AUC:      47.08%\n",
      "  AP:       46.86%\n",
      "  F1:       0.93%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_seeingdark-original\n",
      "샘플 수: 360\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_seeingdark-original: 100%|██████████| 22/22 [01:17<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.57%\n",
      "  AUC:      48.94%\n",
      "  AP:       47.47%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_seeingdark-gaussian_noise\n",
      "샘플 수: 360\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_seeingdark-gaussian_noise: 100%|██████████| 22/22 [00:57<00:00,  2.60s/it]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 51.14%\n",
      "  AUC:      56.01%\n",
      "  AP:       54.61%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_seeingdark-jpeg_compression\n",
      "샘플 수: 360\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_seeingdark-jpeg_compression: 100%|██████████| 22/22 [00:50<00:00,  2.31s/it]\n",
      "/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 51.14%\n",
      "  AUC:      45.12%\n",
      "  AP:       44.24%\n",
      "  F1:       0.00%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stargan-original\n",
      "샘플 수: 3998\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stargan-original: 100%|██████████| 249/249 [00:47<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.45%\n",
      "  AUC:      58.01%\n",
      "  AP:       55.59%\n",
      "  F1:       2.85%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stargan-gaussian_noise\n",
      "샘플 수: 3998\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stargan-gaussian_noise: 100%|██████████| 249/249 [00:47<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.20%\n",
      "  AUC:      49.31%\n",
      "  AP:       49.43%\n",
      "  F1:       0.10%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stargan-jpeg_compression\n",
      "샘플 수: 3998\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stargan-jpeg_compression: 100%|██████████| 249/249 [00:47<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과:\n",
      "  Accuracy: 50.15%\n",
      "  AUC:      51.08%\n",
      "  AP:       51.20%\n",
      "  F1:       0.30%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_stylegan-original\n",
      "샘플 수: 11982\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_stylegan-original:  27%|██▋       | 200/748 [00:38<01:45,  5.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     26\u001b[39m dataloader = DataLoader(\n\u001b[32m     27\u001b[39m     subset,\n\u001b[32m     28\u001b[39m     batch_size=\u001b[32m16\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     drop_last=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 평가\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m metrics = \u001b[43mcalc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcorruption\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     41\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 즉시 결과 출력\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m결과:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/utils/eval/metrics.py:164\u001b[39m, in \u001b[36mMetricsCalculator.evaluate\u001b[39m\u001b[34m(self, model, dataloader, device, name)\u001b[39m\n\u001b[32m    161\u001b[39m images.requires_grad = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Forward pass (model.eval() prevents parameter updates)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Handle different output formats\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs.min() < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m outputs.max() > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/model/method/sasv6.py:564\u001b[39m, in \u001b[36mUnifiedSASv6.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# NPR\u001b[39;00m\n\u001b[32m    562\u001b[39m         artifact = \u001b[38;5;28mself\u001b[39m.model.img2npr(x_preprocessed)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:134\u001b[39m, in \u001b[36mLGrad.classify\u001b[39m\u001b[34m(self, grad)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassify\u001b[39m(\u001b[38;5;28mself\u001b[39m, grad: torch.Tensor) -> torch.Tensor:\n\u001b[32m    127\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m    classification of Gradient image\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m \u001b[33;03m        Logits [B, 1] (positive = fake)\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrad2clf_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.classifier(x)\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:920\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    917\u001b[39m     tensor = tensor.clone()\n\u001b[32m    919\u001b[39m dtype = tensor.dtype\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m mean = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m std = torch.as_tensor(std, dtype=dtype, device=tensor.device)\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (std == \u001b[32m0\u001b[39m).any():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "import random\n",
    "\n",
    "# Evaluation\n",
    "calc = MetricsCalculator()\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        combination_indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] ==corruption\n",
    "        ]\n",
    "\n",
    "        if len(combination_indices) == 0:\n",
    "            print(f\"{dataset_name}-{corruption}: 샘플 없음, 스킵\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"평가 중: {dataset_name}-{corruption}\")\n",
    "        print(f\"샘플 수: {len(combination_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Subset과 DataLoader 생성\n",
    "        subset = Subset(dataset, combination_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            # collate_fn=collate_fn,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        # 평가\n",
    "        metrics = calc.evaluate(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "\n",
    "        # 즉시 결과 출력\n",
    "        print(f\"\\n결과:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:      {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  AP:       {metrics['ap']*100:.2f}%\")\n",
    "        print(f\"  F1:       {metrics['f1']*100:.2f}%\")\n",
    "\n",
    "        # 결과 저장\n",
    "        all_results[(dataset_name, corruption)] = metrics\n",
    "\n",
    "# 전체 결과 테이블 출력\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"전체 결과 요약\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "calc.print_results_table()\n",
    "calc.summarize_by_corruption(all_results)\n",
    "calc.summarize_by_dataset(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
