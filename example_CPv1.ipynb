{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Channel Pruning v1 (CPv1) Example - IMPROVED\n\n## Gradient-Pattern-Aware Channel Pruning\n\n**핵심 차이점 (vs 기존 CPv1)**:\n- ✅ **Pseudo-label 제거**: Label-free minimum deviation 사용\n- ✅ **Gradient corruption sensitivity**: Noise가 gradient pattern을 corrupt하는 정도 측정\n- ✅ **Batch aggregation**: Channel-level로 안정적인 gating\n- ✅ **LGrad 최적화**: Two-stage architecture (img2grad + classifier)에 특화\n\n**기존 CPv1의 문제**:\n- ❌ Pseudo-label이 noisy에서 부정확\n- ❌ Artifact를 noise로 오인 가능\n- ❌ Batch-wise gating으로 불안정\n\n**개선 방법**:\n```python\n# OLD (문제 있음):\npseudo_label = estimate_label(x)  # 부정확!\nsensitivity = |curr - reference[pseudo_label]|\n\n# NEW (IMPROVED):\ndev_real = |curr - real_stats|\ndev_fake = |curr - fake_stats|\nsensitivity = min(dev_real, dev_fake)  # Label-free!\n```\n\n**기대 효과**:\n- Noisy/corrupted image에서 성능 향상\n- Gradient pattern을 robust하게 보존\n- 안정적인 channel selection"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Clear cache\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if any(x in mod for x in ['NPR', 'npr', 'LGrad', 'lgrad', 'networks', 'method', 'channel']):\n",
    "        del sys.modules[mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.visual.visualizer import DatasetVisualizer\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# Channel Pruning v1 import\n",
    "from model.method import (\n",
    "    UnifiedChannelPruningV1,\n",
    "    CPv1Config,\n",
    "    compute_separated_statistics,\n",
    ")\n",
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU and Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 30 18:39:17 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              31W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              24W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              27W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              25W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              25W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              31W / 250W |   4828MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "MODEL_LIST = [\"lgrad\", \"npr\"]\n",
    "MODEL = MODEL_LIST[0]  # \"lgrad\" or \"npr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"corrupted_dataset\"\n",
    "DATASETS = [\n",
    "    \"corrupted_test_data_progan\",\n",
    "    \"corrupted_test_data_stylegan\",\n",
    "    \"corrupted_test_data_stylegan2\",\n",
    "    \"corrupted_test_data_biggan\",\n",
    "]\n",
    "\n",
    "CORRUPTIONS = [\n",
    "    \"original\",\n",
    "    \"gaussian_noise\",\n",
    "    \"jpeg_compression\",\n",
    "]\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 119874\n"
     ]
    }
   ],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root=ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(stylegan_weights, map_location=\"cpu\"),\n",
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(classifier_weights, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded: LGrad\n"
     ]
    }
   ],
   "source": [
    "# LGrad\n",
    "STYLEGAN_WEIGHTS_ROOT = \"model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "CLASSIFIER_WEIGHTS_ROOT = \"model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "\n",
    "# NPR\n",
    "NPR_WEIGHTS_ROOT = \"model/NPR/weights/NPR.pth\"\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    base_model = LGrad(\n",
    "        stylegan_weights=STYLEGAN_WEIGHTS_ROOT,\n",
    "        classifier_weights=CLASSIFIER_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name = \"LGrad\"\n",
    "elif MODEL == \"npr\":\n",
    "    base_model = NPR(\n",
    "        weights=NPR_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name = \"NPR\"\n",
    "\n",
    "print(f\"Base model loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Compute Separated Statistics from Clean Data\n",
    "\n",
    "**중요!** CPv1은 Real clean과 Fake clean의 **분리된** statistics가 필요합니다.\n",
    "\n",
    "- ProGAN의 original (uncorrupted) 데이터로 statistics 수집\n",
    "- **Labels 필수**: Real (0) vs Fake (1) 구분을 위해\n",
    "- 한 번 계산하면 저장해서 재사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProGAN clean samples: 8000\n"
     ]
    }
   ],
   "source": [
    "# Clean data 준비 (ProGAN original - LABELS 필수!)\n",
    "progan_clean_indices = [\n",
    "    i for i, s in enumerate(dataset.samples)\n",
    "    if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"original\"\n",
    "]\n",
    "\n",
    "print(f\"ProGAN clean samples: {len(progan_clean_indices)}\")\n",
    "\n",
    "# Subset & DataLoader (labels 포함!)\n",
    "clean_subset = Subset(dataset, progan_clean_indices)\n",
    "clean_loader = DataLoader(\n",
    "    clean_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing separated statistics from clean data...\n",
      "This may take a few minutes...\n",
      "\n",
      "[CPv1] Computing separated statistics for 106 layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing separated statistics:   5%|▌         | 27/500 [00:44<12:38,  1.60s/it]"
     ]
    }
   ],
   "source": [
    "# Separated statistics 파일 경로\n",
    "STATS_PATH = f\"separated_stats_{MODEL}_progan.pth\"\n",
    "\n",
    "# 기존 statistics가 있으면 로드, 없으면 계산\n",
    "if os.path.exists(STATS_PATH):\n",
    "    print(f\"Loading pre-computed separated statistics from {STATS_PATH}\")\n",
    "    separated_stats = torch.load(STATS_PATH)\n",
    "    print(f\"Statistics loaded for {len(separated_stats)} layers\")\n",
    "else:\n",
    "    print(\"Computing separated statistics from clean data...\")\n",
    "    print(\"This may take a few minutes...\\n\")\n",
    "    \n",
    "    # Target layers: None for auto-detection (detects individual Conv2d/BN layers)\n",
    "    # Note: classifier.layer4 is a Sequential module, not a single layer!\n",
    "    # Auto-detection will find layers like 'classifier.layer4.0.conv1', 'classifier.layer4.2.bn3', etc.\n",
    "    target_layers_for_stats = None\n",
    "    \n",
    "    # Compute (Real/Fake separated!)\n",
    "    separated_stats = compute_separated_statistics(\n",
    "        model=base_model,\n",
    "        dataloader=clean_loader,  # MUST have labels!\n",
    "        target_layers=target_layers_for_stats,\n",
    "        device=DEVICE,\n",
    "        max_batches=None,  # 속도를 위해 50 batches만\n",
    "    )\n",
    "    \n",
    "    # 저장\n",
    "    torch.save(separated_stats, STATS_PATH)\n",
    "    print(f\"\\nStatistics saved to {STATS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Create Channel Pruning v1 Model (IMPROVED)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Config 설정 (IMPROVED!)\nconfig = CPv1Config(\n    model=model_name,\n    target_layers=None,  # Use all auto-detected layers from separated_stats\n    \n    # NEW: Sensitivity method (RECOMMENDED!)\n    sensitivity_method=\"min\",  # Label-free minimum deviation\n    deviation_metric=\"mean\",   # Simple and effective\n    normalize_deviation=False,\n    \n    # NEW: Batch aggregation (RECOMMENDED!)\n    enable_batch_aggregation=True,  # Stable channel-level gating\n    aggregation_method=\"mean\",\n    \n    # Gating parameters\n    temperature_init=1.0,\n    use_learnable_temperature=True,\n    use_channel_bias=True,\n    gating_type=\"soft\",  # or \"hard\"\n    \n    # Optional\n    enable_adaptation=False,  # 선택적\n    device=DEVICE,\n)\n\nprint(\"Configuration (IMPROVED):\")\nprint(f\"  Sensitivity method: {config.sensitivity_method} (LABEL-FREE!)\")\nprint(f\"  Batch aggregation: {config.enable_batch_aggregation}\")\nprint(f\"  Deviation metric: {config.deviation_metric}\")\nprint()\n\n# Model 생성\nmodel = UnifiedChannelPruningV1(\n    base_model=base_model,\n    separated_stats=separated_stats,\n    config=config,\n)\n\nprint(\"\\nChannel Pruning v1 (IMPROVED) model created!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Test-Time Adaptation\n",
    "\n",
    "Noisy validation data로 temperature와 channel bias를 fine-tuning할 수 있습니다.\n",
    "\n",
    "**Skip 가능!** Adaptation 없이도 사용 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adaptation을 원하면 주석 해제\n",
    "# ENABLE_ADAPTATION = True\n",
    "\n",
    "# if ENABLE_ADAPTATION:\n",
    "#     # Noisy validation data 준비\n",
    "#     progan_noisy_indices = [\n",
    "#         i for i, s in enumerate(dataset.samples)\n",
    "#         if s['dataset'] == \"corrupted_test_data_progan\" and s['corruption'] == \"gaussian_noise\"\n",
    "#     ]\n",
    "    \n",
    "#     print(f\"ProGAN noisy samples for adaptation: {len(progan_noisy_indices)}\")\n",
    "    \n",
    "#     noisy_subset = Subset(dataset, progan_noisy_indices[:500])\n",
    "#     noisy_loader = DataLoader(\n",
    "#         noisy_subset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4,\n",
    "#         drop_last=False\n",
    "#     )\n",
    "    \n",
    "#     # Adaptation 실행\n",
    "#     print(\"\\nStarting test-time adaptation...\\n\")\n",
    "#     model.adapt(\n",
    "#         dataloader=noisy_loader,\n",
    "#         epochs=5,\n",
    "#         lr=1e-4,\n",
    "#         verbose=True,\n",
    "#     )\n",
    "#     print(\"\\nAdaptation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Dataset별, Corruption별로 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "calc = MetricsCalculator()\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        combination_indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] == corruption\n",
    "        ]\n",
    "        \n",
    "        if len(combination_indices) == 0:\n",
    "            print(f\"{dataset_name}-{corruption}: 샘플 없음, 스킵\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"평가 중: {dataset_name}-{corruption}\")\n",
    "        print(f\"샘플 수: {len(combination_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Subset과 DataLoader 생성\n",
    "        subset = Subset(dataset, combination_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # 평가\n",
    "        metrics = calc.evaluate(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "        \n",
    "        # 즉시 결과 출력\n",
    "        print(f\"\\n결과:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:      {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  AP:       {metrics['ap']*100:.2f}%\")\n",
    "        print(f\"  F1:       {metrics['f1']*100:.2f}%\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        all_results[(dataset_name, corruption)] = metrics\n",
    "\n",
    "# 전체 결과 테이블 출력\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"전체 결과 요약\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "calc.print_results_table()\n",
    "calc.summarize_by_corruption(all_results)\n",
    "calc.summarize_by_dataset(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learned Parameters 확인\n",
    "\n",
    "각 layer의 temperature가 어떻게 설정/학습되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Learned Parameters (Temperature & Channel Bias)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for sanitized_name, gate in model.gates.items():\n",
    "    # Get original layer name\n",
    "    original_name = model.gate_name_mapping[sanitized_name]\n",
    "    temp_value = gate.temperature.item()\n",
    "    print(f\"{original_name:50s}: temperature = {temp_value:.4f}\")\n",
    "    \n",
    "    # Artifact discriminability\n",
    "    artifact_disc = gate.artifact_discriminability\n",
    "    disc_mean = artifact_disc.mean().item()\n",
    "    disc_std = artifact_disc.std().item()\n",
    "    disc_max = artifact_disc.max().item()\n",
    "    print(f\"{'':50s}  artifact_disc: mean={disc_mean:.4f}, std={disc_std:.4f}, max={disc_max:.4f}\")\n",
    "    \n",
    "    # Channel bias statistics\n",
    "    if config.use_channel_bias:\n",
    "        bias_mean = gate.channel_bias.mean().item()\n",
    "        bias_std = gate.channel_bias.std().item()\n",
    "        bias_min = gate.channel_bias.min().item()\n",
    "        bias_max = gate.channel_bias.max().item()\n",
    "        print(f\"{'':50s}  channel_bias: mean={bias_mean:+.4f}, std={bias_std:.4f}, range=[{bias_min:+.4f}, {bias_max:+.4f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### Channel Pruning v1 (IMPROVED) 핵심:\n\n#### 1. **LGrad의 작동 원리**\n```\nImage → Gradient (StyleGAN) → Classifier → Prediction\n        ↓                      ↓\n    GAN pattern          Pruned channels\n```\n- Real: Natural gradient pattern\n- Fake: GAN-specific gradient pattern  \n- Noise: Corrupts gradient pattern\n\n#### 2. **핵심 아이디어**\n- Gradient pattern을 robust하게 보존하는 채널 유지\n- Noise corruption에 민감한 채널 제거\n\n#### 3. **방법론 (IMPROVED)**\n\n**OLD (기존 CPv1)**:\n```python\n# ❌ Pseudo-label 의존\npseudo_label = estimate_label(x)  # Noisy에서 부정확!\nif pseudo_label == Fake:\n    sensitivity = |curr - fake_stats|  # Artifact를 noise로 오인\nelse:\n    sensitivity = |curr - real_stats|\n```\n\n**NEW (Gradient-Pattern-Aware)**:\n```python\n# ✅ Label-free minimum deviation\ndev_real = |curr - real_stats|\ndev_fake = |curr - fake_stats|\nsensitivity = min(dev_real, dev_fake)\n\n# Clean: close to at least one → small\n# Noisy: far from both → large\n```\n\n**Score 계산**:\n```python\ndiscriminability = |fake_stats - real_stats|  # Gradient pattern 차이\nscore = discriminability / sensitivity\n\n# High score: Strong pattern detection + Low corruption sensitivity → KEEP\n# Low score: Weak detection + High sensitivity → PRUNE\n```\n\n#### 4. **주요 개선사항**\n\n| 측면 | 기존 CPv1 | IMPROVED CPv1 |\n|------|-----------|---------------|\n| Pseudo-label | ❌ 필요 (부정확) | ✅ 불필요 (label-free) |\n| Sensitivity | ❌ Label-aware (오류 가능) | ✅ Minimum deviation |\n| Gating | ❌ Batch-wise (불안정) | ✅ Channel-level (안정) |\n| LGrad 이해 | ❌ 일반적 | ✅ Gradient-specific |\n\n#### 5. **vs Channel Reweight v1**\n\n| 특징 | CRv1 | CPv1 (IMPROVED) |\n|------|------|-----------------|\n| Statistics | Mixed (Real+Fake) | Separated (Real, Fake) |\n| Artifact info | ❌ 구분 불가 | ✅ 보존 |\n| Method | Reweighting | Gradient-pattern-aware pruning |\n| Label-free | ✅ Yes | ✅ Yes (improved!) |\n\n### 작동 원리:\n\n1. **Pre-compute**: Real/Fake clean gradient features의 separated statistics\n2. **Test time**: Noisy gradient → classifier features\n3. **Sensitivity**: `min(|curr - real|, |curr - fake|)` (gradient corruption)\n4. **Discriminability**: `|fake - real|` (pattern difference)\n5. **Score**: `disc / sens`\n6. **Gating**: High score channels만 유지\n\n### 다음 단계:\n- ✅ Baseline (no gating)과 성능 비교\n- ✅ 기존 CPv1과 성능 비교\n- ✅ CRv1과 성능 비교\n- □ SGS, SAS 등 다른 방법들과 비교\n- □ NPR 모델에도 적용"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}