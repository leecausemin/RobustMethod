{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4f61aa",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "from typing import Optional, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.visual.visualizer import DatasetVisualizer\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# SGS method import\n",
    "from model.method.sgs import LGradSGS, SGSConfig\n",
    "from model.LGrad.lgrad_model import LGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c327e",
   "metadata": {},
   "source": [
    "# GPU and Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf394e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:2\"\n",
    "MODEL_LIST = [\"lgrad\", \"npr\"]\n",
    "MODEL = MODEL_LIST[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d73d",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d50a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/workspace/robust_deepfake_ai/corrupted_dataset\"\n",
    "DATASETS = [\"corrupted_test_data_biggan\", \"corrupted_test_data_crn\", \"corrupted_test_data_cyclegan\", \"corrupted_test_data_deepfake\", \"corrupted_test_data_gaugan\", \"corrupted_test_data_imle\", \"corrupted_test_data_progan\", \"corrupted_test_data_san\", \"corrupted_test_data_seeingdark\", \"corrupted_test_data_stargan\", \"corrupted_test_data_stylegan\", \"corrupted_test_data_stylegan2\", \"corrupted_test_data_whichfaceisreal\"]\n",
    "CORRUPTIONS = [\"original\", \"contrast\", \"fog\", \"gaussian_noise\", \"jpeg_compression\", \"motion_blur\", \"pixelate\"]\n",
    "if MODEL == \"lgrad\":\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(224), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root= ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba635981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset sampling\n",
    "# from torch.utils.data import Subset\n",
    "# import random\n",
    "\n",
    "# samples_per_combination = 500\n",
    "# selected_indices = []\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# for dataset_name in DATASETS:\n",
    "#     for corruption in CORRUPTIONS:\n",
    "#         combination_indices = [\n",
    "#             i for i, s in enumerate(dataset.samples)\n",
    "#             if s['dataset'] == dataset_name and s['corruption'] == corruption]\n",
    "\n",
    "#         # 1000개 샘플링 (부족하면 전부 사용)\n",
    "#         n_samples = min(samples_per_combination, len(combination_indices))\n",
    "#         if n_samples > 0:\n",
    "#             sampled = random.sample(combination_indices, n_samples)\n",
    "#             selected_indices.extend(sampled)\n",
    "\n",
    "#         print(f\"{dataset_name}-{corruption}: {len(combination_indices)} -> {n_samples} samples\")\n",
    "\n",
    "# # Subset 생성\n",
    "# subset_dataset = Subset(dataset, selected_indices)\n",
    "# print(f\"\\nTotal: {len(dataset)} -> {len(subset_dataset)} samples\")\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     subset_dataset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3209cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "#     pin_memory=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization\n",
    "# viz = DatasetVisualizer(seed=1)\n",
    "\n",
    "# viz(dataset, corruption=\"all\", n_samples=3, label=\"real\")\n",
    "\n",
    "# viz.stats(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2f66d",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR\n",
    "from model.method.norm import LGradNORM, NORMConfig, UnifiedNORM\n",
    "from model.LGrad.lgrad_model import LGrad\n",
    "from model.NPR.npr_model import NPR\n",
    "\n",
    "#LGrad\n",
    "STYLEGAN_WEIGHTS_ROOT=\"/workspace/robust_deepfake_ai/model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "CLASSIFIER_WEIGHTS_ROOT=\"/workspace/robust_deepfake_ai/model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "\n",
    "#NPR\n",
    "NPR_WEIGHTS_ROOT=\"/workspace/robust_deepfake_ai/model/NPR/weights/NPR.pth\"\n",
    "\n",
    "if MODEL == \"lgrad\":\n",
    "    model = LGrad(\n",
    "        stylegan_weights=STYLEGAN_WEIGHTS_ROOT,\n",
    "        classifier_weights=CLASSIFIER_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name=\"LGrad\"\n",
    "    LAMBDA=0.03\n",
    "    DELTA=0.01\n",
    "    ITERATIONS=5\n",
    "    STEP_SIZE=0.1\n",
    "elif MODEL == \"npr\":\n",
    "    model = NPR(\n",
    "        weights=NPR_WEIGHTS_ROOT,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    model_name=\"NPR\"\n",
    "    LAMBDA=0.005\n",
    "    DELTA=0.01\n",
    "    ITERATIONS=3\n",
    "    STEP_SIZE=0.1\n",
    "\n",
    "\n",
    "# NORM\n",
    "norm_config = NORMConfig(\n",
    "    source_sum=1024,\n",
    "    model=model_name,\n",
    "    adaptation_target=\"model\",\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Apply NORM to FreqNorm's internal LGrad classifier\n",
    "model = UnifiedNORM(model, norm_config)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.method.sgs import SGSConfig, UnifiedSGS\n",
    "sgs_config = SGSConfig(\n",
    "    K=4,\n",
    "    model=model_name,\n",
    "    denoise_target=\"artifact\",\n",
    "    huber_tv_lambda=LAMBDA,\n",
    "    huber_tv_delta=DELTA,\n",
    "    huber_tv_iterations=ITERATIONS,\n",
    "    huber_tv_step_size=STEP_SIZE,\n",
    "\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "model = UnifiedSGS(model, sgs_config)\n",
    "\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     # 모델이 사용하는 resize 크기 (LGrad의 경우 256)\n",
    "#     import torch\n",
    "#     import torch.nn.functional as F\n",
    "#     target_size = (256, 256)\n",
    "\n",
    "#     images = []\n",
    "#     for item in batch:\n",
    "#         img = item[0]\n",
    "#         if isinstance(img, torch.Tensor):\n",
    "#             # 크기가 다르면 미리 resize (모델 내부 transform과 동일하게)\n",
    "#             if img.shape[-2:] != target_size:\n",
    "#                 img = F.interpolate(\n",
    "#                     img.unsqueeze(0),\n",
    "#                     size=target_size,\n",
    "#                     mode='bilinear',\n",
    "#                     align_corners=False\n",
    "#                 ).squeeze(0)\n",
    "#             images.append(img)\n",
    "#         else:\n",
    "#             images.append(img)\n",
    "\n",
    "#     images = torch.stack(images)\n",
    "#     labels = torch.tensor([item[1] for item in batch])\n",
    "\n",
    "#     if len(batch[0]) == 3:\n",
    "#         metadata = [item[2] for item in batch]\n",
    "#         return images, labels, metadata\n",
    "#     return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c722a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "import random\n",
    "\n",
    "# # 설정\n",
    "# samples_per_combination = 500\n",
    "# random.seed(42)\n",
    "\n",
    "# Evaluation\n",
    "calc = MetricsCalculator()\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        # 해당 조합의 인덱스 찾기\n",
    "        combination_indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] ==corruption\n",
    "        ]\n",
    "\n",
    "        if len(combination_indices) == 0:\n",
    "            print(f\"{dataset_name}-{corruption}: 샘플 없음, 스킵\")\n",
    "            continue\n",
    "\n",
    "        # # 샘플링\n",
    "        # n_samples = min(samples_per_combination, len(combination_indices))\n",
    "        # sampled_indices = random.sample(combination_indices, n_samples)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"평가 중: {dataset_name}-{corruption}\")\n",
    "        print(f\"샘플 수: {len(combination_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Subset과 DataLoader 생성\n",
    "        subset = Subset(dataset, combination_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            # collate_fn=collate_fn,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        # 평가\n",
    "        metrics = calc.evaluate(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "\n",
    "        # 즉시 결과 출력\n",
    "        print(f\"\\n결과:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:      {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  AP:       {metrics['ap']*100:.2f}%\")\n",
    "        print(f\"  F1:       {metrics['f1']*100:.2f}%\")\n",
    "\n",
    "        # 결과 저장\n",
    "        all_results[(dataset_name, corruption)] = metrics\n",
    "\n",
    "# 전체 결과 테이블 출력\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"전체 결과 요약\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "calc.print_results_table()\n",
    "calc.summarize_by_corruption(all_results)\n",
    "calc.summarize_by_dataset(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# calc = MetricsCalculator()\n",
    "\n",
    "# # 조합별 평가\n",
    "# results = calc.evaluate(\n",
    "#     model=model,\n",
    "#     dataloader=dataloader,\n",
    "#     device=DEVICE,\n",
    "#     name=f\"{dataset_name}-{corruption}\"\n",
    "# )\n",
    "\n",
    "# # 결과 출력\n",
    "# calc.print_results_table(results)\n",
    "# calc.summarize_by_corruption(results)\n",
    "# calc.summarize_by_dataset(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
