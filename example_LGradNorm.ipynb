{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4f61aa",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2585317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "from typing import Optional, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data.dataset import CorruptedDataset\n",
    "from utils.visual.visualizer import DatasetVisualizer\n",
    "from utils.eval.metrics import PredictionCollector, MetricsCalculator\n",
    "\n",
    "# NORM method import\n",
    "from model.method.method import LGradNORM, NORMConfig\n",
    "from model.LGrad.lgrad_model import LGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c327e",
   "metadata": {},
   "source": [
    "# GPU and Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1212de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 13 13:46:02 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              28W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              25W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              28W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              27W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              32W / 250W |   4840MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf394e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:1\"\n",
    "MODEL_LIST = [\"lgrad\", \"npr\"]\n",
    "MODEL = MODEL_LIST[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zmhk35wflg",
   "metadata": {},
   "source": [
    "# NORM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aak3xcgvo6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM Config:\n",
      "  Source Sum: 256\n",
      "  Adaptation Target: grad_model\n",
      "  Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# NORM 파라미터 설정\n",
    "SOURCE_SUM = 256 # 소스 도메인 누적 배치 크기 (높을수록 소스 통계 유지)\n",
    "ADAPTATION_TARGET = \"grad_model\"  # \"classifier\", \"grad_model\", \"both\"\n",
    "\n",
    "# Config 생성\n",
    "norm_config = NORMConfig(\n",
    "    source_sum=SOURCE_SUM,\n",
    "    adaptation_target=ADAPTATION_TARGET,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"NORM Config:\")\n",
    "print(f\"  Source Sum: {SOURCE_SUM}\")\n",
    "print(f\"  Adaptation Target: {ADAPTATION_TARGET}\")\n",
    "print(f\"  Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d73d",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d50a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/workspace/robust_deepfake_ai/corrupted_dataset\"\n",
    "DATASETS = [\"corrupted_test_data_biggan\", \"corrupted_test_data_crn\", \"corrupted_test_data_cyclegan\", \"corrupted_test_data_deepfake\", \"corrupted_test_data_gaugan\", \"corrupted_test_data_imle\", \"corrupted_test_data_progan\", \"corrupted_test_data_san\", \"corrupted_test_data_seeingdark\", \"corrupted_test_data_stargan\", \"corrupted_test_data_stylegan\", \"corrupted_test_data_stylegan2\", \"corrupted_test_data_whichfaceisreal\"]\n",
    "CORRUPTIONS = [\"original\", \"contrast\", \"fog\", \"gaussian_noise\", \"jpeg_compression\", \"motion_blur\", \"pixelate\"]\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5739f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 632303\n"
     ]
    }
   ],
   "source": [
    "dataset = CorruptedDataset(\n",
    "    root= ROOT,\n",
    "    datasets=DATASETS,\n",
    "    corruptions=CORRUPTIONS,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba635981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset sampling\n",
    "# from torch.utils.data import Subset\n",
    "# import random\n",
    "\n",
    "# samples_per_combination = 500\n",
    "# selected_indices = []\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# for dataset_name in DATASETS:\n",
    "#     for corruption in CORRUPTIONS:\n",
    "#         combination_indices = [\n",
    "#             i for i, s in enumerate(dataset.samples)\n",
    "#             if s['dataset'] == dataset_name and s['corruption'] == corruption]\n",
    "\n",
    "#         # 1000개 샘플링 (부족하면 전부 사용)\n",
    "#         n_samples = min(samples_per_combination, len(combination_indices))\n",
    "#         if n_samples > 0:\n",
    "#             sampled = random.sample(combination_indices, n_samples)\n",
    "#             selected_indices.extend(sampled)\n",
    "\n",
    "#         print(f\"{dataset_name}-{corruption}: {len(combination_indices)} -> {n_samples} samples\")\n",
    "\n",
    "# # Subset 생성\n",
    "# subset_dataset = Subset(dataset, selected_indices)\n",
    "# print(f\"\\nTotal: {len(dataset)} -> {len(subset_dataset)} samples\")\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     subset_dataset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3209cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "#     pin_memory=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae30e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization\n",
    "# viz = DatasetVisualizer(seed=1)\n",
    "\n",
    "# viz(dataset, corruption=\"all\", n_samples=3, label=\"real\")\n",
    "\n",
    "# viz.stats(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2f66d",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bec3d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base LGrad model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(stylegan_weights, map_location=\"cpu\"),\n",
      "/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(classifier_weights, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded!\n",
      "\n",
      "Applying NORM adaptation...\n",
      "LGradNORM ready!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGrad(\n",
       "  (grad_model): StyleGANDiscriminator(\n",
       "    (input0): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer0): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer1): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input1): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer2): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer3): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input2): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer4): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer5): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): DownsamplingLayer()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input3): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer6): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer7): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): DownsamplingLayer()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input4): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer8): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer9): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): DownsamplingLayer()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input5): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer10): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer11): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): BlurLayer()\n",
       "      (downsample): DownsamplingLayer()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (input6): ConvBlock(\n",
       "      (mbstd): Identity()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer12): ConvBlock(\n",
       "      (mbstd): MiniBatchSTDLayer()\n",
       "      (blur): Identity()\n",
       "      (downsample): Identity()\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer13): DenseBlock(\n",
       "      (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (layer14): DenseBlock(\n",
       "      (activate): Identity()\n",
       "    )\n",
       "    (downsample): DownsamplingLayer()\n",
       "  )\n",
       "  (classifier): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LGrad weights\n",
    "STYLEGAN_WEIGHTS_ROOT = \"/workspace/robust_deepfake_ai/model/LGrad/weights/karras2019stylegan-bedrooms-256x256_discriminator.pth\"\n",
    "CLASSIFIER_WEIGHTS_ROOT = \"/workspace/robust_deepfake_ai/model/LGrad/weights/LGrad-Pretrained-Model/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth\"\n",
    "\n",
    "print(\"Loading base LGrad model...\")\n",
    "base_lgrad = LGrad(\n",
    "    stylegan_weights=STYLEGAN_WEIGHTS_ROOT,\n",
    "    classifier_weights=CLASSIFIER_WEIGHTS_ROOT,\n",
    "    device=DEVICE\n",
    ")\n",
    "print(\"Base model loaded!\")\n",
    "\n",
    "print(\"\\nApplying NORM adaptation...\")\n",
    "model = LGradNORM(base_lgrad, norm_config)\n",
    "print(\"LGradNORM ready!\")\n",
    "\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e04296f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Identity-1          [-1, 3, 256, 256]               0\n",
      "          Identity-2          [-1, 3, 256, 256]               0\n",
      "          Identity-3         [-1, 64, 256, 256]               0\n",
      "         LeakyReLU-4         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-5         [-1, 64, 256, 256]             256\n",
      "          Identity-6         [-1, 64, 256, 256]               0\n",
      "          Identity-7         [-1, 64, 256, 256]               0\n",
      "          Identity-8         [-1, 64, 256, 256]               0\n",
      "         LeakyReLU-9         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-10         [-1, 64, 256, 256]          36,928\n",
      "         Identity-11         [-1, 64, 256, 256]               0\n",
      "        BlurLayer-12         [-1, 64, 256, 256]               0\n",
      "         Identity-13        [-1, 128, 128, 128]               0\n",
      "        LeakyReLU-14        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-15        [-1, 128, 128, 128]          73,856\n",
      "         Identity-16        [-1, 128, 128, 128]               0\n",
      "         Identity-17        [-1, 128, 128, 128]               0\n",
      "         Identity-18        [-1, 128, 128, 128]               0\n",
      "        LeakyReLU-19        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-20        [-1, 128, 128, 128]         147,584\n",
      "         Identity-21        [-1, 128, 128, 128]               0\n",
      "        BlurLayer-22        [-1, 128, 128, 128]               0\n",
      "         Identity-23          [-1, 256, 64, 64]               0\n",
      "        LeakyReLU-24          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-25          [-1, 256, 64, 64]         295,168\n",
      "         Identity-26          [-1, 256, 64, 64]               0\n",
      "         Identity-27          [-1, 256, 64, 64]               0\n",
      "         Identity-28          [-1, 256, 64, 64]               0\n",
      "        LeakyReLU-29          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-30          [-1, 256, 64, 64]         590,080\n",
      "         Identity-31          [-1, 256, 64, 64]               0\n",
      "        BlurLayer-32          [-1, 256, 64, 64]               0\n",
      "DownsamplingLayer-33          [-1, 512, 32, 32]               0\n",
      "        LeakyReLU-34          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-35          [-1, 512, 32, 32]       1,180,160\n",
      "         Identity-36          [-1, 512, 32, 32]               0\n",
      "         Identity-37          [-1, 512, 32, 32]               0\n",
      "         Identity-38          [-1, 512, 32, 32]               0\n",
      "        LeakyReLU-39          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-40          [-1, 512, 32, 32]       2,359,808\n",
      "         Identity-41          [-1, 512, 32, 32]               0\n",
      "        BlurLayer-42          [-1, 512, 32, 32]               0\n",
      "DownsamplingLayer-43          [-1, 512, 16, 16]               0\n",
      "        LeakyReLU-44          [-1, 512, 16, 16]               0\n",
      "        ConvBlock-45          [-1, 512, 16, 16]       2,359,808\n",
      "         Identity-46          [-1, 512, 16, 16]               0\n",
      "         Identity-47          [-1, 512, 16, 16]               0\n",
      "         Identity-48          [-1, 512, 16, 16]               0\n",
      "        LeakyReLU-49          [-1, 512, 16, 16]               0\n",
      "        ConvBlock-50          [-1, 512, 16, 16]       2,359,808\n",
      "         Identity-51          [-1, 512, 16, 16]               0\n",
      "        BlurLayer-52          [-1, 512, 16, 16]               0\n",
      "DownsamplingLayer-53            [-1, 512, 8, 8]               0\n",
      "        LeakyReLU-54            [-1, 512, 8, 8]               0\n",
      "        ConvBlock-55            [-1, 512, 8, 8]       2,359,808\n",
      "         Identity-56            [-1, 512, 8, 8]               0\n",
      "         Identity-57            [-1, 512, 8, 8]               0\n",
      "         Identity-58            [-1, 512, 8, 8]               0\n",
      "        LeakyReLU-59            [-1, 512, 8, 8]               0\n",
      "        ConvBlock-60            [-1, 512, 8, 8]       2,359,808\n",
      "         Identity-61            [-1, 512, 8, 8]               0\n",
      "        BlurLayer-62            [-1, 512, 8, 8]               0\n",
      "DownsamplingLayer-63            [-1, 512, 4, 4]               0\n",
      "        LeakyReLU-64            [-1, 512, 4, 4]               0\n",
      "        ConvBlock-65            [-1, 512, 4, 4]       2,359,808\n",
      "MiniBatchSTDLayer-66            [-1, 513, 4, 4]               0\n",
      "         Identity-67            [-1, 513, 4, 4]               0\n",
      "         Identity-68            [-1, 512, 4, 4]               0\n",
      "        LeakyReLU-69            [-1, 512, 4, 4]               0\n",
      "        ConvBlock-70            [-1, 512, 4, 4]       2,364,416\n",
      "        LeakyReLU-71                  [-1, 512]               0\n",
      "       DenseBlock-72                  [-1, 512]       4,194,816\n",
      "         Identity-73                    [-1, 1]               0\n",
      "       DenseBlock-74                    [-1, 1]             513\n",
      "StyleGANDiscriminator-75                    [-1, 1]               0\n",
      "           Conv2d-76         [-1, 64, 128, 128]           9,408\n",
      "      BatchNorm2d-77         [-1, 64, 128, 128]             128\n",
      "             ReLU-78         [-1, 64, 128, 128]               0\n",
      "        MaxPool2d-79           [-1, 64, 64, 64]               0\n",
      "           Conv2d-80           [-1, 64, 64, 64]           4,096\n",
      "      BatchNorm2d-81           [-1, 64, 64, 64]             128\n",
      "             ReLU-82           [-1, 64, 64, 64]               0\n",
      "           Conv2d-83           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-84           [-1, 64, 64, 64]             128\n",
      "             ReLU-85           [-1, 64, 64, 64]               0\n",
      "           Conv2d-86          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-87          [-1, 256, 64, 64]             512\n",
      "           Conv2d-88          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-89          [-1, 256, 64, 64]             512\n",
      "             ReLU-90          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-91          [-1, 256, 64, 64]               0\n",
      "           Conv2d-92           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-93           [-1, 64, 64, 64]             128\n",
      "             ReLU-94           [-1, 64, 64, 64]               0\n",
      "           Conv2d-95           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-96           [-1, 64, 64, 64]             128\n",
      "             ReLU-97           [-1, 64, 64, 64]               0\n",
      "           Conv2d-98          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-99          [-1, 256, 64, 64]             512\n",
      "            ReLU-100          [-1, 256, 64, 64]               0\n",
      "      Bottleneck-101          [-1, 256, 64, 64]               0\n",
      "          Conv2d-102           [-1, 64, 64, 64]          16,384\n",
      "     BatchNorm2d-103           [-1, 64, 64, 64]             128\n",
      "            ReLU-104           [-1, 64, 64, 64]               0\n",
      "          Conv2d-105           [-1, 64, 64, 64]          36,864\n",
      "     BatchNorm2d-106           [-1, 64, 64, 64]             128\n",
      "            ReLU-107           [-1, 64, 64, 64]               0\n",
      "          Conv2d-108          [-1, 256, 64, 64]          16,384\n",
      "     BatchNorm2d-109          [-1, 256, 64, 64]             512\n",
      "            ReLU-110          [-1, 256, 64, 64]               0\n",
      "      Bottleneck-111          [-1, 256, 64, 64]               0\n",
      "          Conv2d-112          [-1, 128, 64, 64]          32,768\n",
      "     BatchNorm2d-113          [-1, 128, 64, 64]             256\n",
      "            ReLU-114          [-1, 128, 64, 64]               0\n",
      "          Conv2d-115          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-116          [-1, 128, 32, 32]             256\n",
      "            ReLU-117          [-1, 128, 32, 32]               0\n",
      "          Conv2d-118          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-119          [-1, 512, 32, 32]           1,024\n",
      "          Conv2d-120          [-1, 512, 32, 32]         131,072\n",
      "     BatchNorm2d-121          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-122          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-123          [-1, 512, 32, 32]               0\n",
      "          Conv2d-124          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-125          [-1, 128, 32, 32]             256\n",
      "            ReLU-126          [-1, 128, 32, 32]               0\n",
      "          Conv2d-127          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-128          [-1, 128, 32, 32]             256\n",
      "            ReLU-129          [-1, 128, 32, 32]               0\n",
      "          Conv2d-130          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-131          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-132          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-133          [-1, 512, 32, 32]               0\n",
      "          Conv2d-134          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-135          [-1, 128, 32, 32]             256\n",
      "            ReLU-136          [-1, 128, 32, 32]               0\n",
      "          Conv2d-137          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-138          [-1, 128, 32, 32]             256\n",
      "            ReLU-139          [-1, 128, 32, 32]               0\n",
      "          Conv2d-140          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-141          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-142          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-143          [-1, 512, 32, 32]               0\n",
      "          Conv2d-144          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-145          [-1, 128, 32, 32]             256\n",
      "            ReLU-146          [-1, 128, 32, 32]               0\n",
      "          Conv2d-147          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-148          [-1, 128, 32, 32]             256\n",
      "            ReLU-149          [-1, 128, 32, 32]               0\n",
      "          Conv2d-150          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-151          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-152          [-1, 512, 32, 32]               0\n",
      "      Bottleneck-153          [-1, 512, 32, 32]               0\n",
      "          Conv2d-154          [-1, 256, 32, 32]         131,072\n",
      "     BatchNorm2d-155          [-1, 256, 32, 32]             512\n",
      "            ReLU-156          [-1, 256, 32, 32]               0\n",
      "          Conv2d-157          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 16, 16]             512\n",
      "            ReLU-159          [-1, 256, 16, 16]               0\n",
      "          Conv2d-160         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 16, 16]           2,048\n",
      "          Conv2d-162         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-163         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-164         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-165         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-166          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-167          [-1, 256, 16, 16]             512\n",
      "            ReLU-168          [-1, 256, 16, 16]               0\n",
      "          Conv2d-169          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-170          [-1, 256, 16, 16]             512\n",
      "            ReLU-171          [-1, 256, 16, 16]               0\n",
      "          Conv2d-172         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-173         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-174         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-175         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-176          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 16, 16]             512\n",
      "            ReLU-178          [-1, 256, 16, 16]               0\n",
      "          Conv2d-179          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 16, 16]             512\n",
      "            ReLU-181          [-1, 256, 16, 16]               0\n",
      "          Conv2d-182         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-184         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-185         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-186          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-187          [-1, 256, 16, 16]             512\n",
      "            ReLU-188          [-1, 256, 16, 16]               0\n",
      "          Conv2d-189          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-190          [-1, 256, 16, 16]             512\n",
      "            ReLU-191          [-1, 256, 16, 16]               0\n",
      "          Conv2d-192         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-193         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-194         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-195         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-196          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-197          [-1, 256, 16, 16]             512\n",
      "            ReLU-198          [-1, 256, 16, 16]               0\n",
      "          Conv2d-199          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-200          [-1, 256, 16, 16]             512\n",
      "            ReLU-201          [-1, 256, 16, 16]               0\n",
      "          Conv2d-202         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-203         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-204         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-205         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-206          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-207          [-1, 256, 16, 16]             512\n",
      "            ReLU-208          [-1, 256, 16, 16]               0\n",
      "          Conv2d-209          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-210          [-1, 256, 16, 16]             512\n",
      "            ReLU-211          [-1, 256, 16, 16]               0\n",
      "          Conv2d-212         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-213         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-214         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-215         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-216          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-217          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-218          [-1, 512, 16, 16]               0\n",
      "          Conv2d-219            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-220            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-221            [-1, 512, 8, 8]               0\n",
      "          Conv2d-222           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-223           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-224           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-225           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-226           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-227           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-228            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-229            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-230            [-1, 512, 8, 8]               0\n",
      "          Conv2d-231            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-232            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-233            [-1, 512, 8, 8]               0\n",
      "          Conv2d-234           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-235           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-236           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-237           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-238            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-239            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-240            [-1, 512, 8, 8]               0\n",
      "          Conv2d-241            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-242            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-243            [-1, 512, 8, 8]               0\n",
      "          Conv2d-244           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-245           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-246           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-247           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-248           [-1, 2048, 1, 1]               0\n",
      "          Linear-249                    [-1, 1]           2,049\n",
      "          ResNet-250                    [-1, 1]               0\n",
      "           LGrad-251                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 46,552,706\n",
      "Trainable params: 46,552,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 990.27\n",
      "Params size (MB): 177.58\n",
      "Estimated Total Size (MB): 1168.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a660081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     # 모델이 사용하는 resize 크기 (LGrad의 경우 256)\n",
    "#     import torch\n",
    "#     import torch.nn.functional as F\n",
    "#     target_size = (256, 256)\n",
    "\n",
    "#     images = []\n",
    "#     for item in batch:\n",
    "#         img = item[0]\n",
    "#         if isinstance(img, torch.Tensor):\n",
    "#             # 크기가 다르면 미리 resize (모델 내부 transform과 동일하게)\n",
    "#             if img.shape[-2:] != target_size:\n",
    "#                 img = F.interpolate(\n",
    "#                     img.unsqueeze(0),\n",
    "#                     size=target_size,\n",
    "#                     mode='bilinear',\n",
    "#                     align_corners=False\n",
    "#                 ).squeeze(0)\n",
    "#             images.append(img)\n",
    "#         else:\n",
    "#             images.append(img)\n",
    "\n",
    "#     images = torch.stack(images)\n",
    "#     labels = torch.tensor([item[1] for item in batch])\n",
    "\n",
    "#     if len(batch[0]) == 3:\n",
    "#         metadata = [item[2] for item in batch]\n",
    "#         return images, labels, metadata\n",
    "#     return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c722a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LGradNORM Evaluation on Corrupted Datasets\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-original\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-original: 100%|██████████| 250/250 [00:47<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LGradNORM] 결과:\n",
      "  Accuracy: 79.77%\n",
      "  AUC:      90.75%\n",
      "  AP:       87.86%\n",
      "  F1:       82.75%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-contrast\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-contrast: 100%|██████████| 250/250 [00:47<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LGradNORM] 결과:\n",
      "  Accuracy: 59.70%\n",
      "  AUC:      64.49%\n",
      "  AP:       59.03%\n",
      "  F1:       70.79%\n",
      "\n",
      "============================================================\n",
      "평가 중: corrupted_test_data_biggan-fog\n",
      "샘플 수: 4000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted_test_data_biggan-fog:   5%|▌         | 13/250 [00:02<00:54,  4.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     31\u001b[39m dataloader = DataLoader(\n\u001b[32m     32\u001b[39m     subset,\n\u001b[32m     33\u001b[39m     batch_size=\u001b[32m16\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     drop_last=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 평가\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m metrics = \u001b[43mcalc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcorruption\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 즉시 결과 출력\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[LGradNORM] 결과:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/utils/eval/metrics.py:164\u001b[39m, in \u001b[36mMetricsCalculator.evaluate\u001b[39m\u001b[34m(self, model, dataloader, device, name)\u001b[39m\n\u001b[32m    161\u001b[39m images.requires_grad = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Forward pass (model.eval() prevents parameter updates)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Handle different output formats\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs.min() < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m outputs.max() > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/model/method/method.py:155\u001b[39m, in \u001b[36mLGradNORM.forward\u001b[39m\u001b[34m(self, x, return_grad)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03mForward pass with NORM adaptation.\u001b[39;00m\n\u001b[32m    145\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    152\u001b[39m \u001b[33;03m    grad (optional): [B, 3, 256, 256] gradient images\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()  \u001b[38;5;66;03m# Keep in eval mode (but BatchNorm will adapt)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:150\u001b[39m, in \u001b[36mLGrad.forward\u001b[39m\u001b[34m(self, x, return_grad)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m    x: Input images [B, 3, H, W], range [0, 1]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m    grad (optional): [B, 3, 256, 256] gradient images\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    149\u001b[39m grad = \u001b[38;5;28mself\u001b[39m.img2grad(x)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_grad:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/model/LGrad/lgrad_model.py:132\u001b[39m, in \u001b[36mLGrad.classify\u001b[39m\u001b[34m(self, grad)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassify\u001b[39m(\u001b[38;5;28mself\u001b[39m, grad: torch.Tensor) -> torch.Tensor:\n\u001b[32m    125\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m    classification of Gradient image\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m \u001b[33;03m        Logits [B, 1] (positive = fake)\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrad2clf_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.classifier(x)\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/robust_deepfake_ai/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:920\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    917\u001b[39m     tensor = tensor.clone()\n\u001b[32m    919\u001b[39m dtype = tensor.dtype\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m mean = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m std = torch.as_tensor(std, dtype=dtype, device=tensor.device)\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (std == \u001b[32m0\u001b[39m).any():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "import random\n",
    "\n",
    "# Evaluation with LGradNORM\n",
    "print(\"=\"*80)\n",
    "print(\"LGradNORM Evaluation on Corrupted Datasets\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "calc = MetricsCalculator()\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    for corruption in CORRUPTIONS:\n",
    "        # 해당 조합의 인덱스 찾기\n",
    "        combination_indices = [\n",
    "            i for i, s in enumerate(dataset.samples)\n",
    "            if s['dataset'] == dataset_name and s['corruption'] == corruption\n",
    "        ]\n",
    "\n",
    "        if len(combination_indices) == 0:\n",
    "            print(f\"{dataset_name}-{corruption}: 샘플 없음, 스킵\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"평가 중: {dataset_name}-{corruption}\")\n",
    "        print(f\"샘플 수: {len(combination_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Subset과 DataLoader 생성\n",
    "        subset = Subset(dataset, combination_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        # 평가\n",
    "        metrics = calc.evaluate(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            device=DEVICE,\n",
    "            name=f\"{dataset_name}-{corruption}\"\n",
    "        )\n",
    "\n",
    "        # 즉시 결과 출력\n",
    "        print(f\"\\n[LGradNORM] 결과:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  AUC:      {metrics['auc']*100:.2f}%\")\n",
    "        print(f\"  AP:       {metrics['ap']*100:.2f}%\")\n",
    "        print(f\"  F1:       {metrics['f1']*100:.2f}%\")\n",
    "\n",
    "        # 결과 저장\n",
    "        all_results[(dataset_name, corruption)] = metrics\n",
    "\n",
    "# 전체 결과 테이블 출력\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"LGradNORM - 전체 결과 요약\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "calc.print_results_table()\n",
    "calc.summarize_by_corruption(all_results)\n",
    "calc.summarize_by_dataset(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# calc = MetricsCalculator()\n",
    "\n",
    "# # 조합별 평가\n",
    "# results = calc.evaluate(\n",
    "#     model=model,\n",
    "#     dataloader=dataloader,\n",
    "#     device=DEVICE,\n",
    "#     name=f\"{dataset_name}-{corruption}\"\n",
    "# )\n",
    "\n",
    "# # 결과 출력\n",
    "# calc.print_results_table(results)\n",
    "# calc.summarize_by_corruption(results)\n",
    "# calc.summarize_by_dataset(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
